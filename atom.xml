<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://twFR.github.io</id>
    <title>🌟谭先生✨</title>
    <updated>2021-01-17T12:10:52.101Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://twFR.github.io"/>
    <link rel="self" href="https://twFR.github.io/atom.xml"/>
    <subtitle>敲不出代码的程序猿的🏠</subtitle>
    <logo>https://twFR.github.io/images/avatar.png</logo>
    <icon>https://twFR.github.io/favicon.ico</icon>
    <rights>All rights reserved 2021, 🌟谭先生✨</rights>
    <entry>
        <title type="html"><![CDATA[Time Format]]></title>
        <id>https://twFR.github.io/post/time-format/</id>
        <link href="https://twFR.github.io/post/time-format/">
        </link>
        <updated>2021-01-16T06:28:09.000Z</updated>
        <content type="html"><![CDATA[<p>昨天听高人说golang的time format很有意思，之前没有用到过，专门了解了一下<br>
当我试着随便如下打印当前时间：</p>
<pre><code>fmt.Println(time.Now().Format(&quot;2021年1月16日&quot; ))
</code></pre>
<p>output:</p>
<pre><code>16161年1月16日
</code></pre>
<p>大惑不解，googel了一下，说是一定要用固定的时间去格式化，Go的蛋辰，果然仪式感还是很重要的，如下</p>
<pre><code>fmt.Println(time.Now().Format(&quot;2006年1月2日 15:04:05&quot; ))
fmt.Println(time.Now().Format(&quot;2006年1月2日&quot; ))
</code></pre>
<p>output:</p>
<pre><code>2021年1月16日 18:37:18
2021年1月16日
</code></pre>
<p>稍微看下源码<br>
在AppendFormat方法里调用nextStdChunk方法，确实是用循环去对固定的时间检索：</p>
<pre><code>// nextStdChunk finds the first occurrence of a std string in
// layout and returns the text before, the std string, and the text after.
func nextStdChunk(layout string) (prefix string, std int, suffix string) {
	for i := 0; i &lt; len(layout); i++ {
		switch c := int(layout[i]); c {
		case 'J': // January, Jan
			if len(layout) &gt;= i+3 &amp;&amp; layout[i:i+3] == &quot;Jan&quot; {
				if len(layout) &gt;= i+7 &amp;&amp; layout[i:i+7] == &quot;January&quot; {
					return layout[0:i], stdLongMonth, layout[i+7:]
				}
				if !startsWithLowerCase(layout[i+3:]) {
					return layout[0:i], stdMonth, layout[i+3:]
				}
			}

		case 'M': // Monday, Mon, MST
			if len(layout) &gt;= i+3 {
				if layout[i:i+3] == &quot;Mon&quot; {
					if len(layout) &gt;= i+6 &amp;&amp; layout[i:i+6] == &quot;Monday&quot; {
						return layout[0:i], stdLongWeekDay, layout[i+6:]
					}
					if !startsWithLowerCase(layout[i+3:]) {
						return layout[0:i], stdWeekDay, layout[i+3:]
					}
				}
				if layout[i:i+3] == &quot;MST&quot; {
					return layout[0:i], stdTZ, layout[i+3:]
				}
			}

		case '0': // 01, 02, 03, 04, 05, 06, 002
			if len(layout) &gt;= i+2 &amp;&amp; '1' &lt;= layout[i+1] &amp;&amp; layout[i+1] &lt;= '6' {
				return layout[0:i], std0x[layout[i+1]-'1'], layout[i+2:]
			}
			if len(layout) &gt;= i+3 &amp;&amp; layout[i+1] == '0' &amp;&amp; layout[i+2] == '2' {
				return layout[0:i], stdZeroYearDay, layout[i+3:]
			}

		case '1': // 15, 1
			if len(layout) &gt;= i+2 &amp;&amp; layout[i+1] == '5' {
				return layout[0:i], stdHour, layout[i+2:]
			}
			return layout[0:i], stdNumMonth, layout[i+1:]

		case '2': // 2006, 2
			if len(layout) &gt;= i+4 &amp;&amp; layout[i:i+4] == &quot;2006&quot; {
				return layout[0:i], stdLongYear, layout[i+4:]
			}
			return layout[0:i], stdDay, layout[i+1:]

		case '_': // _2, _2006, __2
			if len(layout) &gt;= i+2 &amp;&amp; layout[i+1] == '2' {
				//_2006 is really a literal _, followed by stdLongYear
				if len(layout) &gt;= i+5 &amp;&amp; layout[i+1:i+5] == &quot;2006&quot; {
					return layout[0 : i+1], stdLongYear, layout[i+5:]
				}
				return layout[0:i], stdUnderDay, layout[i+2:]
			}
			if len(layout) &gt;= i+3 &amp;&amp; layout[i+1] == '_' &amp;&amp; layout[i+2] == '2' {
				return layout[0:i], stdUnderYearDay, layout[i+3:]
			}

		case '3':
			return layout[0:i], stdHour12, layout[i+1:]

		case '4':
			return layout[0:i], stdMinute, layout[i+1:]

		case '5':
			return layout[0:i], stdSecond, layout[i+1:]

		case 'P': // PM
			if len(layout) &gt;= i+2 &amp;&amp; layout[i+1] == 'M' {
				return layout[0:i], stdPM, layout[i+2:]
			}

		case 'p': // pm
			if len(layout) &gt;= i+2 &amp;&amp; layout[i+1] == 'm' {
				return layout[0:i], stdpm, layout[i+2:]
			}

		case '-': // -070000, -07:00:00, -0700, -07:00, -07
			if len(layout) &gt;= i+7 &amp;&amp; layout[i:i+7] == &quot;-070000&quot; {
				return layout[0:i], stdNumSecondsTz, layout[i+7:]
			}
			if len(layout) &gt;= i+9 &amp;&amp; layout[i:i+9] == &quot;-07:00:00&quot; {
				return layout[0:i], stdNumColonSecondsTZ, layout[i+9:]
			}
			if len(layout) &gt;= i+5 &amp;&amp; layout[i:i+5] == &quot;-0700&quot; {
				return layout[0:i], stdNumTZ, layout[i+5:]
			}
			if len(layout) &gt;= i+6 &amp;&amp; layout[i:i+6] == &quot;-07:00&quot; {
				return layout[0:i], stdNumColonTZ, layout[i+6:]
			}
			if len(layout) &gt;= i+3 &amp;&amp; layout[i:i+3] == &quot;-07&quot; {
				return layout[0:i], stdNumShortTZ, layout[i+3:]
			}

		case 'Z': // Z070000, Z07:00:00, Z0700, Z07:00,
			if len(layout) &gt;= i+7 &amp;&amp; layout[i:i+7] == &quot;Z070000&quot; {
				return layout[0:i], stdISO8601SecondsTZ, layout[i+7:]
			}
			if len(layout) &gt;= i+9 &amp;&amp; layout[i:i+9] == &quot;Z07:00:00&quot; {
				return layout[0:i], stdISO8601ColonSecondsTZ, layout[i+9:]
			}
			if len(layout) &gt;= i+5 &amp;&amp; layout[i:i+5] == &quot;Z0700&quot; {
				return layout[0:i], stdISO8601TZ, layout[i+5:]
			}
			if len(layout) &gt;= i+6 &amp;&amp; layout[i:i+6] == &quot;Z07:00&quot; {
				return layout[0:i], stdISO8601ColonTZ, layout[i+6:]
			}
			if len(layout) &gt;= i+3 &amp;&amp; layout[i:i+3] == &quot;Z07&quot; {
				return layout[0:i], stdISO8601ShortTZ, layout[i+3:]
			}

		case '.': // .000 or .999 - repeated digits for fractional seconds.
			if i+1 &lt; len(layout) &amp;&amp; (layout[i+1] == '0' || layout[i+1] == '9') {
				ch := layout[i+1]
				j := i + 1
				for j &lt; len(layout) &amp;&amp; layout[j] == ch {
					j++
				}
				// String of digits must end here - only fractional second is all digits.
				if !isDigit(layout, j) {
					std := stdFracSecond0
					if layout[i+1] == '9' {
						std = stdFracSecond9
					}
					std |= (j - (i + 1)) &lt;&lt; stdArgShift
					return layout[0:i], std, layout[j:]
				}
			}
		}
	}
	return layout, 0, &quot;&quot;
}
</code></pre>
<p>记时间方法也挺简单 6(年)1(月)2(日)3(时)4(分)5(秒),严重怀疑只是为了简单。 看来我还是太单纯</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[operator summary]]></title>
        <id>https://twFR.github.io/post/operator-summary/</id>
        <link href="https://twFR.github.io/post/operator-summary/">
        </link>
        <updated>2020-10-21T01:45:45.000Z</updated>
        <content type="html"><![CDATA[<h2 id="概念">概念</h2>
<p>Operator 是一组软件，可用于降低运行其他软件的操作复杂程度，从技术上讲，Operator 是一种打包、部署和管理 Kubernetes 应用程序的方法。<br>
operator可以：</p>
<ul>
<li>重复安装和升级</li>
<li>持续对每个系统组件执行运行状况检查</li>
<li>汇总现场工程师了解的情况并将其传输给所有用户，而非一两个用户<br>
operator与servie broker相比：</li>
<li>Service Broker 朝着实现应用程序的编程式发现和部署的目标前进了一步。但它并非一个长时间运行的进程，所以无法执行第 2 天操作，如升级、故障转移或扩展。它在安装时提供对可调参数的自定义和参数化，而 Operator 则可持续监控集群的当前状态。非集群服务仍非常适合于 Service Broker，但也存在合适于这些服务的 Operator</li>
</ul>
<h2 id="operator-framework">operator framework</h2>
<ul>
<li><strong>operator SDK</strong>   辅助开发者根据自身专业知识，引导，构建，测试和包装其operator</li>
<li><strong>Operator Lifecycle</strong> Manager 控制集群中operator的安装，升级和基于角色的访问控制（RBAC）</li>
<li><strong>Operator Registry</strong> 存储CSV和CRD以便在集群中创建，并存储有关软件包和频道的operator元数据</li>
<li>OperatorHub</li>
<li>Operator Metering</li>
</ul>
<h3 id="常用术语">常用术语</h3>
<ul>
<li><strong>bundle</strong> 在bndle fromat中，bundle是CSV，manifests以及metadata的集合</li>
<li><strong>CatalogSource</strong> 定义应用程序的CSV CRD和软件包仓库</li>
<li><strong>channel</strong>  channel为 Operator 定义更新流，用于为订阅者推出更新。channel head指向该channel的最新版本。例如，stable channel中会包含 Operator 的所有稳定版本，按由旧到新的顺序排列</li>
<li><strong>CSV</strong> CSV是利用operator的manifest创建的YAML清单，可辅助olm在集群中运行operator。附带的manifest还可用于在用户界面填充徽标 描述和版本信息。此外，CSV 还是运行 Operator 所需的技术信息来源，类似于其需要的 RBAC 规则及其管理或依赖的自定义资源 (CR)。</li>
<li><strong>InstallPlan</strong> ip是一个列出了为自动安装或升级 CSV 而需创建的资源的计算列表</li>
<li><strong>OperatorGroup</strong> og将部署在同一命名空间中的所有 Operator 配置为og对象，以便在一系列命名空间或集群范围内监视其 CR。</li>
<li><strong>Subscription</strong> sub通过跟踪软件包中的频道来保持 CSV 最新。</li>
</ul>
<h3 id="operator-lifecycle-manager">Operator Lifecycle Manager</h3>
<p>olm可帮助用户安装 更新和管理所有operator的生命周期</p>
<ol>
<li>olm资源
<ul>
<li>由olm oerator和catalog oerator管理的CRD
<ul>
<li><strong>CSV</strong> OLM 需要与 Operator 相关的元数据，以确保它可以在集群中安全运行，并在发布新版 Operator 时提供有关如何应用更新的信息。此外，CSV 还是运行 Operator 所需的技术信息来源，例如其管理或依赖的自定义资源 (CR)、RBAC 规则、集群要求和安装策略。此信息告诉 OLM 如何创建所需资源并将 Operator 设置为 Deployment。</li>
<li><strong>catalogsource</strong> CatalogSource 代表 OLM 可查询的元数据存储，以发现和安装 Operator 及其依赖项。<br>
catsrc有三种sourceTypes：<br>
- 带有<code>image</code>引用的<code>grpc</code>：OLM拉取镜像并运行pod<br>
- 带有<code>address</code>引用的<code>grpc</code>:OLM会尝试给定地址的gRPC API<br>
- <code>internal</code>或<code>configmap</code>: OLM 解析 ConfigMap 数据，并运行一个可以为其提供 gRPC API 的 pod</li>
<li><strong>Subscription</strong> 将 Operator 与 CatalogSource 关联的自定义资源,Subscription 描述了要订阅 Operator 软件包的哪个频道，以及是自动还是手动执行更新。如果设置为自动，Subscription 会确保由 OLM 管理并升级 Operator，以确保集群中始终运行最新版本。</li>
<li><strong>InstallPlan</strong> ip定义了要创建的一组资源，用于安装或升级到 CSV 定义的 ClusterService 的特定版本。</li>
<li><strong>OperatorGroup</strong> 为 OLM 安装的 Operator 提供多租户配置。OperatorGroup 选择目标命名空间，在其中为其成员 Operator 生成所需的 RBAC 访问权限。</li>
</ul>
</li>
</ul>
</li>
<li>olm架构<br>
由olm operator和catalog operator管理的CRD：csv，ip，catsrc，sub，og<br>
由olm operator创建的资源：sa，clusterRoles，clusterRoleBindings<br>
由catalog operator创建的资源 CRD CSV
<ul>
<li><strong>Catalog Operator</strong><br>
Catalog Operator 负责解析和安装 CSV 及其指定的所需资源。另外还负责监视频道中的 CatalogSource 中是否有软件包更新，并将其升级（可选择自动）至最新可用版本。<br>
用户可创建 Subscription 资源，该资源将配置所需软件包、频道和 CatalogSource，以便从中拉取更新。找到更新后，便会代表用户将适当 InstallPlan 写入命名空间。<br>
catalog operator工作流：
<ol>
<li>连接到集群中的每个 CatalogSource</li>
<li>监视是否有用户创建的未解析 InstallPlan，如果有：
<ul>
<li>查找与请求名称相匹配的 CSV，并将此 CSC 添加为已解析的资源。</li>
<li>对于每个受管或所需 CRD，将其添加为已解析的资源。</li>
<li>对于每个所需 CRD，找到管理相应 CRD 的 CSV。</li>
</ul>
</li>
<li>监视是否有已解析的 InstallPlan 并为其创建已发现的所有资源（用户批准或自动）。</li>
<li>监视 CatalogSource 和 Subscription，并根据它们创建 InstallPlan。</li>
</ol>
</li>
<li><strong>OLM operator</strong><br>
集群中存在 CSV 中指定需要的资源后，OLM Operator 将负责部署由 CSV 资源定义的应用程序。OLM Operator 不负责创建所需资源， Catalog Operator 来创建这些资源<br>
OLM operator工作流：
<ol>
<li>监视命名空间中的 ClusterServiceVersion (CSV)，并检查是否满足要求</li>
<li>满足要求，运行CSV安装策略</li>
</ol>
<pre><code>&gt; CSV必须为og的活跃成员才可运行该安装策略
</code></pre>
</li>
<li>Catalog Registry<br>
Catalog Registry 存储 CSV 和 CRD 以便在集群中创建，并存储有关软件包和频道的元数据。</li>
</ul>
</li>
<li>OG
<ul>
<li>og成员资格，满足以下任一条件：
<ol>
<li>Operator 的 CSV 与 OperatorGroup 存在于同一命名空间中。</li>
<li>Operator 的 CSV InstallMode 支持 OperatorGroup 所针对的命名空间集。<br>
InstallMode和受支持的og
<ul>
<li>OwnNamespace：Operator 可以是选择其自有命名空间的 OperatorGroup 的成员。</li>
<li>SingleNamespace：Operator 可以是选择某一个命名空间的 OperatorGroup 的成员。</li>
<li>MultiNamespace：Operator 可以是选择多个命名空间的 OperatorGroup 的成员。</li>
<li>AllNamespaces：Operator 可以是选择所有命名空间的 OperatorGroup 的成员（目标命名空间集为空字符串 &quot;&quot;）<br>
全局 OperatorGroup 的 status.namespace 包含空字符串 (&quot;&quot;)，而该字符串会向正在使用的 Operator 发出信号，要求其监视所有命名空间。<br>
OLM 会在每个 OperatorGroup 的目标命名空间中复制 OperatorGroup 的所有活跃成员 CSV。复制 CSV 的目的在于告诉目标命名空间的用户，特定 Operator 已配置为监视在此创建的资源。</li>
</ul>
</li>
</ol>
</li>
</ul>
</li>
</ol>
<ul>
<li>基于角色的访问控制<br>
创建 OperatorGroup 时，会生成三个 ClusterRole。每个 ClusterRole 均包含一个 AggregationRule，后者设置了 ClusterRoleSelector 以匹配标签，
<ul>
<li>&lt;operatorgroup_name&gt;-admin  （olm.opgroup.permissions/aggregate-to-admin: &lt;operatorgroup_name&gt;）</li>
<li>&lt;operatorgroup_name&gt;-edit    （olm.opgroup.permissions/aggregate-to-edit: &lt;operatorgroup_name&gt;）</li>
<li>&lt;operatorgroup_name&gt;-view   （olm.opgroup.permissions/aggregate-to-view: &lt;operatorgroup_name&gt;）<br>
CSV 成为 OperatorGroup 的活跃成员时，只要该 CSV 正在使用 AllNamespaces InstallMode 来监视所有命名空间，且没有因 InterOperatorGroupOwnerConflict 原因处于故障状态，便会生成以下 RBAC 资源。</li>
<li>来自 CRD 的每个 API 资源的 ClusterRole （&lt;kind&gt;.&lt;group&gt;-&lt;version&gt;-admin &lt;kind&gt;.&lt;group&gt;-&lt;version&gt;-edit &lt;kind&gt;.&lt;group&gt;-&lt;version&gt;-view &lt;kind&gt;.&lt;group&gt;-&lt;version&gt;-view-crdview）</li>
<li>来自APIService，针对每个 API 资源生成的 ClusterRole （&lt;kind&gt;.&lt;group&gt;-&lt;version&gt;-admin &lt;kind&gt;.&lt;group&gt;-&lt;version&gt;-edit &lt;kind&gt;.&lt;group&gt;-&lt;version&gt;-view）</li>
<li>额外的role和rolebinding</li>
</ul>
</li>
<li>og交集<br>
如果两个 OperatorGroup 的目标命名空间集的交集不是空集，且根据 olm.providedAPIs 注解的定义，所提供的 API 集的交集也不是空集，则称这两个 OperatorGroup 的提供的 API 有交集。</li>
<li>og故障<br>
1. 如果一个命名空间中存在多个 OperatorGroup，则在该命名空间中创建的所有 CSV 均会变成故障状态，故障原因为：TooManyOperatorGroups。一旦命名空间中 OperatorGroup 的数量变成 1，因该原因处于故障状态的 CSV 将转变为等待处理状态。<br>
2. 如果 CSV 的 InstallMode 不支持其命名空间中 OperatorGroup 的目标命名空间选择，CSV 将变为故障状态，故障原因为 UnsupportedOperatorGroup。一旦 OperatorGroup 的目标命名空间选择变为受支持的配置，或 CSV 的 InstallMode 经修改后支持 OperatorGroup 的目标命名空间选择，因该原因处于故障状态的 CSV 将转变为等待处理状态。</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[prime filter ]]></title>
        <id>https://twFR.github.io/post/prime-fliter/</id>
        <link href="https://twFR.github.io/post/prime-fliter/">
        </link>
        <updated>2020-06-02T07:01:03.000Z</updated>
        <content type="html"><![CDATA[<p>使用并发来做一个素数筛</p>
<pre><code>package main

import &quot;fmt&quot;

func main() {
	ch :=GenerateNatural()
	for i:=0;i&lt;100;i++{
		prime := &lt;-ch                              // 第一个一定是素数
		fmt.Printf(&quot;%v: %v\n&quot;, i+1, prime)
		ch = primeFliter(ch,prime)
	}
}

// 生成一个自然数列
func GenerateNatural() chan int {
	ch := make(chan int)
	go func() {
		for i := 2; ; i++ {
			ch &lt;- i
		}
	}()
	return ch
}

// 根据prime过滤，过滤后的第一个一定是素数
func primeFliter(in &lt;- chan int,prime int) chan int{
	out := make(chan int)
	go func() {
		for {
			if i:=&lt;-in;i%prime!=0{
				out &lt;- i
			}
		}
	}()
	return out
}
</code></pre>
<p>GenerateNatural和PrimeFilter函数内部都启动了新的Goroutine，当main函数不再使用管道时后台Goroutine有泄漏的风险。可以通过context包来避免这个问题，下面是改进的素数筛实现：</p>
<pre><code>package main

import (
	&quot;context&quot;
	&quot;fmt&quot;
)

func GenerateNatural(ctx context.Context) chan int {
	ch := make(chan int)
	go func() {
		for i := 2; ; i++ {
			select {
			case &lt;-ctx.Done():
				return
			case ch &lt;- i:
			}
		}
	}()
	return ch
}

func primeFilter(ctx context.Context, in &lt;-chan int, prime int) chan int {
	out := make(chan int)
	go func() {
		for {
			if i := &lt;-in; i%prime != 0 {
				select {
				case &lt;-ctx.Done():
					return
				case out &lt;- i:
				}
			}
		}
	}()
	return out
}

func main() {

	ctx, cancel := context.WithCancel(context.Background())
	ch := GenerateNatural(ctx)
	for i := 0; i &lt; 1000; i++ {
		prime := &lt;-ch
		fmt.Printf(&quot;%v: %v\n&quot;, i+1, prime)
		ch = primeFilter(ctx, ch, prime)
	}

	cancel()   // main函数完成时，调用cancel(),通知后台goroutine退出，即ctx.Done收到信号
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[golang unsafe package]]></title>
        <id>https://twFR.github.io/post/golang-unsafe-package/</id>
        <link href="https://twFR.github.io/post/golang-unsafe-package/">
        </link>
        <updated>2020-05-08T06:27:11.000Z</updated>
        <content type="html"><![CDATA[<p>使用unsafe.Pointer来取切片的属性</p>
<pre><code>func testPointer() {
	s := make([]int, 9, 20)
	s = append(s, 2)
	len := *(*int)(unsafe.Pointer(uintptr(unsafe.Pointer(&amp;s)) + uintptr(8)))
	cap := *(*int)(unsafe.Pointer(uintptr(unsafe.Pointer(&amp;s)) + uintptr(16)))

	dataPointer := *(*int)(unsafe.Pointer(&amp;s))
	data1 := *(*int)(unsafe.Pointer(uintptr(dataPointer)))

	fmt.Printf(&quot;len: %d cap:%d \n&quot;, len, cap)
	fmt.Printf(&quot;dataPointer: %d  data1:%d \n&quot;, dataPointer, data1)

	i := 0
	for {
		if i &gt;= len {
			break
		}
		fmt.Printf(&quot;data%d:%d \n&quot;, i, *(*int)(unsafe.Pointer(uintptr(dataPointer) + uintptr(8*i))))
		i++
	}
}
</code></pre>
<p>unsafe 包绕过了 Go 的类型系统，达到直接操作内存的目的，使用它有一定的风险性。但是在某些场景下，使用 unsafe 包提供的函数会提升代码的效率，Go 源码中也是大量使用 unsafe 包。</p>
<p>unsafe 包定义了 Pointer 和三个函数：</p>
<p>通过三个函数可以获取变量的大小(Sizeof)、偏移(Offsetof)、对齐(Alignof)等信息。</p>
<p>uintptr 可以和 unsafe.Pointer 进行相互转换，uintptr 可以进行数学运算。这样，通过 uintptr 和 unsafe.Pointer 的结合就解决了 Go 指针不能进行数学运算的限制。</p>
<p>通过 unsafe 相关函数，可以获取结构体私有成员的地址，进而对其做进一步的读写操作，突破 Go 的类型安全限制。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[docker]]></title>
        <id>https://twFR.github.io/post/docker-file/</id>
        <link href="https://twFR.github.io/post/docker-file/">
        </link>
        <updated>2020-04-07T02:34:00.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p>reference: <a href="https://docs.docker.com/engine/reference/builder/">docker官方文档</a></p>
</blockquote>
<h2 id="dockerfile">dockerfile</h2>
<ul>
<li>dockerfile必须以<code>FROM</code>指令开始。<code>ARG</code>是唯一可以早于<code>FROM</code>执行的指令，查看<a href="#interact">ARG和FROM的交互</a></li>
<li>dockerfile中以<code>#</code>来标示注释，注释会在dockerfile被执行前移除掉，以免对命令产生影响</li>
</ul>
<h3 id="解析器指令">解析器指令</h3>
<p>解析器指令放在最上面，以<code># directive=value</code>的形式来声明，一旦注释 空行或者builder指令执行，docker就不会再去招解析器指令，而是把它当成注释。<br>
下面几种是不符合规范的场景：</p>
<pre><code># direc \  
 tive=value
</code></pre>
<p>△ 换行不符合规范</p>
<pre><code># directive=value1
# directive=value2
FROM ImageName
</code></pre>
<p>△ 出现两次</p>
<pre><code>FROM ImageName
# directive=value
</code></pre>
<p>△ 在builder指令后面，会被认为是注释</p>
<pre><code># About my dockerfile
# directive=value
FROM ImageName
</code></pre>
<p>△ 在注释后面，会被认为是注释</p>
<pre><code># unknowndirective=value
# knowndirective=value
</code></pre>
<p>△ 未知的解释器指令，会被认为是注释，第二行同样会被认为是注释</p>
<pre><code>#directive=value
# directive =value
#	directive= value
# directive = value
#	  dIrEcTiVe=value
</code></pre>
<p>△ 上面几种写法会被认为是同一种写法，即无视空格，不区分大小写</p>
<p>支持的解释器指令</p>
<ul>
<li>syntax<br>
# syntax=[remote image reference]<br>
这是用buldkit才会使用到的，为了指定构建当前dokcerfile的dokcerfile构建器的位置</li>
<li>escape<br>
# escape=\ (backslash) || # escape=` (backtick)<br>
escape定义转义字符，转义字符不会在<code>RUN</code>指令中执行<br>
例如在windows中将转义字符设置成`  很有用，因为windows目录格式是<code>C:\\</code>，但是在dockerfile里面会解析成<code>C:\</code>，就会找不到对应目录</li>
</ul>
<h3 id="环境变量">环境变量</h3>
<p>环境变量以$variable_name 或者 ${variable_name}格式，同样支持以下bash风格的格式：</p>
<ul>
<li>${variable:-word}  如果<code>veriable</code>设置了值，结果就是这个值。如果没有，就是<code>word</code>结果，<code>word</code>可以是定值也可以是其他变量</li>
<li>${variable:+word}  如果<code>veriable</code>设置了值，结果就是<code>word</code>。如果没有，就是空<br>
如下示例：</li>
</ul>
<pre><code>ENV abc=hello
ENV abc=bye def=$abc
ENV ghi=$abc
</code></pre>
<p><code>def</code>的值为<code>hello</code>，而 <code>ghi</code>值为<code>bye</code>官方是如下解释的</p>
<blockquote>
<p>Environment variable substitution will use the same value for each variable throughout the entire instruction. In other words</p>
</blockquote>
<p>讲道理没看特明白，但是个人土味理解应该是说每行算一个<code>entire instruction</code>,这行的值都是不会变化的，所以<code>def</code>还是用的上一行的<code>hello</code>值，而<code>ghi</code> 则可以取到上一行执行后的结果</p>
<h3 id="dockerignore-file">.dockerignore file</h3>
<p><code>.dockerignore</code> file其实和git里面的.<code>gitignore</code>文件类似，docker CLI在发送context的时候会先寻找这个文件，然后将这个文件和文件里面的指定模式的文件去除掉，不发送给docker daemon。需要注意的是<code>!</code>这个符号的用法：</p>
<pre><code>*.md                       //去掉所有md结尾的文件
!README*.md          //README开头的md文件不去除
README-secret.md  // README-secret.md作为特例要去除
</code></pre>
<p>这里表示去掉所有markdown文件。但是不去除README相关的文件，除了README-secret.md这个文件</p>
<h3 id="from">FROM</h3>
<p>三种格式：</p>
<pre><code>FROM [--platform=&lt;platform&gt;] &lt;image&gt; [AS &lt;name&gt;]
</code></pre>
<pre><code>FROM [--platform=&lt;platform&gt;] &lt;image&gt;[:&lt;tag&gt;] [AS &lt;name&gt;]
</code></pre>
<pre><code>FROM [--platform=&lt;platform&gt;] &lt;image&gt;[@&lt;digest&gt;] [AS &lt;name&gt;]
</code></pre>
<p><code>FROM</code>开始一个构建阶段，并且指定后面刚好构建指令的基础镜像</p>
<ul>
<li><code>FROM</code>可以在一个dokcerfile里面出现多次，构建多个构建镜像。只要在下一次<code>FROM</code>指令之前记住上一次image ID，两次构建就可以相互用来。每次<code>FROM</code>指令开始会清除上一次的指令</li>
<li><code>AS name</code>是可选的，如果使用了，可以在下一次的<code>FROM</code>使用 <code>COPY --from=&lt;name&gt;</code>来关联上一次的构建镜像</li>
<li><code>tag</code>和<code>digest</code>也是可选的，默认为<code>latest</code></li>
</ul>
<h4 id="a-nameinteractarg和from的交互a"><a name="interact">ARG和FROM的交互</a></h4>
<p>FROM的变量是通过ARG来定义的，所以ARG是有可能先于FROM执行的，但是此时ARG是在构建阶段之外定义的，只能在FROM指令里面使用，在其他指令使用需要在执行一次没有值的ARG</p>
<pre><code>ARG VERSION=latest
FROM busybox:$VERSION
ARG VERSION     //空值ARG取上一次ARG的值
RUN echo $VERSION &gt; image_version
</code></pre>
<h3 id="run">RUN</h3>
<p>两种格式：</p>
<pre><code>RUN &lt;command&gt;(shell form,the command is run in a shell, which by default is /bin/sh -c on Linux or cmd /S /C on Windows))
</code></pre>
<pre><code>RUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] (exec form)
</code></pre>
<p>RUN指令将在当前layer顶部的新layer执行命令，提交结果，生成的镜像将用于dockerfile下一步<br>
例：</p>
<pre><code>RUN /bin/bash -c 'source $HOME/.bashrc; echo $HOME'
</code></pre>
<pre><code>RUN [&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;echo hello&quot;]  //execform 是解析称json数组的，所以只能用&quot;，不能用'
</code></pre>
<p>execform不会调用shell，如RUN[&quot;echo,&quot;<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>H</mi><mi>O</mi><mi>M</mi><mi>E</mi><mi mathvariant="normal">&quot;</mi><mo>]</mo><mo separator="true">,</mo><mi mathvariant="normal">不</mi><mi mathvariant="normal">会</mi><mi mathvariant="normal">在</mi></mrow><annotation encoding="application/x-tex">HOME&quot;],不会在</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault" style="margin-right:0.10903em;">M</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mord">&quot;</span><span class="mclose">]</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord cjk_fallback">不</span><span class="mord cjk_fallback">会</span><span class="mord cjk_fallback">在</span></span></span></span>HOME上进行变量替换。要执行shell，需要这样：RUN [ &quot;sh&quot;, &quot;-c&quot;, &quot;echo $HOME&quot; ]。当使用execform并直接执行shell时（例如在shell表单中），是由shell进行环境变量扩展，而不是docker。<br>
RUN指令的缓存不会自动失效。 诸如RUN apt-get dist-upgrade -y之类的指令的存将在下一个构建期间重用。 可以使用--no-cache标志使RUN指令的缓存无效，例如docker build --no-cache</p>
<h3 id="cmd">CMD</h3>
<p>三种格式：</p>
<pre><code>CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;] (exec form, this is the preferred form)
</code></pre>
<pre><code>CMD [&quot;param1&quot;,&quot;param2&quot;] (as default parameters to ENTRYPOINT) //使用JSON数组格式指定，即只能使用 &quot;,不能使用'
</code></pre>
<pre><code>CMD command param1 param2 (shell form)   //在/ bin / sh -c中执行
</code></pre>
<p>CMD指令的首要目的在于为启动的容器指定默认要运行的程序，且其运行结束后，容器也将终止；不过， CMD指定的命令其可以被 docker run的命令行选项所覆盖 .在Dockerfile中可以存在多个 CMD指令，但仅最后一个会生效<br>
如果用户为docker run指定了参数，则它们将覆盖CMD中指定的默认值</p>
<h4 id="run和cmd的区别">RUN和CMD的区别</h4>
<blockquote>
<p>Do not confuse RUN with CMD. RUN actually runs a command and commits the result; CMD does not execute anything at build time, but specifies the intended command for the image.<br>
RUN执行了命令并提交了结果，但是CMD在build期间没有执行热河东西，但是为镜像指定了预期的命令</p>
</blockquote>
<h3 id="entrypoint">ENTRYPOINT</h3>
<p>两种格式：</p>
<pre><code>ENTRYPOINT [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] (exec form)
</code></pre>
<pre><code>ENTRYPOINT command param1 param2 (shell form)
</code></pre>
<p>类似 CMD指令的功能，用于为容器指定默认运行程序，从而使得容器像是一个单独的可执行程序</p>
<p>与CMD不同的是，由 ENTRYPOINT启动的程序不会被 docker run命令行指定的参数所覆盖，而且，这些命令行参数会被当作参数传递给 ENTRYPOINT指定指定的程序 ,ocker run 命令传入的命令参数会覆盖CMD指令的内容并且附加到ENTRYPOINT命令最后做为其参数使用, docker run命令的 --entrypoint选项的参数可覆盖ENTRYPOINT指令指定的程序<br>
Dockerfile文件中也可以存在多个 ENTRYPOINT指令，但仅有最后一个会生效</p>
<h4 id="cmd和entyypoint交互">CMD和ENTYYPOINT交互</h4>
<p>Dockerfile应该指定CMD或ENTRYPOINT命令中的至少一个。<br>
使用容器作为可执行文件时，应定义ENTRYPOINT。<br>
CMD应该用作定义ENTRYPOINT命令或在容器中执行临时命令的默认参数的方式。<br>
下表显示了针对不同ENTRYPOINT / CMD组合执行的命令：</p>
<table>
<thead>
<tr>
<th></th>
<th>No ENTRYPOINT</th>
<th>ENTRYPOINT exec_entry p1_entry</th>
<th>ENTRYPOINT [“exec_entry”, “p1_entry”]</th>
</tr>
</thead>
<tbody>
<tr>
<td>No CMD</td>
<td>error, not allowed</td>
<td>/bin/sh -c exec_entry p1_entry</td>
<td>exec_entry p1_entry</td>
</tr>
<tr>
<td>CMD [“exec_cmd”, “p1_cmd”]</td>
<td>exec_cmd p1_cmd</td>
<td>/bin/sh -c exec_entry p1_entry</td>
<td>exec_entry p1_entry exec_cmd p1_cmd</td>
</tr>
<tr>
<td>CMD [“p1_cmd”, “p2_cmd”]</td>
<td>p1_cmd p2_cmd</td>
<td>/bin/sh -c exec_entry p1_entry</td>
<td>exec_entry p1_entry p1_cmd p2_cmd</td>
</tr>
<tr>
<td>CMD exec_cmd p1_cmd</td>
<td>/bin/sh -c exec_cmd p1_cmd</td>
<td>/bin/sh -c exec_entry p1_entry</td>
<td>exec_entry p1_entry /bin/sh -c exec_cmd p1_cmd</td>
</tr>
</tbody>
</table>
<h3 id="copy">COPY</h3>
<p>两种形式</p>
<pre><code>COPY [--chown=&lt;user&gt;:&lt;group&gt;] &lt;src&gt;... &lt;dest&gt;
COPY [--chown=&lt;user&gt;:&lt;group&gt;] [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;]  //在路径中有空白字符时通常使用此形式
</code></pre>
<p><code>--chown</code>仅支持用户构建linux容器的dockerfile<br>
&lt;src&gt;：要复制的源文件或目录，支持使用通配符<br>
&lt;dest&gt;：目标路径，即正在创建的 image的文件系统路径；建议为 &lt;dest&gt;使用绝对路径，&lt;dest&gt;绝对路径为镜像中的路径，而不是宿主机的路径。否则， <code>COPY</code>指定则以 <code>WORKDIR</code>为其起始路径</p>
<ul>
<li>文件复制准则
<ol>
<li>&lt;src&gt;必须是build上下文中的路径，即只能放在workshop这个工作目录下，不能是其父目录中的文件</li>
<li>如果&lt;src&gt;是目录，其内部文件或者子目录会被递归复制，但&lt;src&gt;目录自身不会被复制</li>
<li>如果指定了多个&lt;src&gt;，或在&lt;src&gt;中使用了通配符，则&lt;dest&gt;必须是一个目录，且&lt;dest&gt;目录必须以<code>/</code>结尾</li>
<li>如果&lt;dest&gt;事先不存在，它将会被自动创建，这包括其父目录路径<br>
例：</li>
</ol>
</li>
</ul>
<pre><code>
[root@node1 ~]# mkdir img1/
[root@node1 ~]# cd img1/
[root@node1 img1]# ls
[root@node1 img1]# vim index.html
&lt;h1&gt;twfr.github.io &lt;/h1&gt;
[root@node1 img1]# vim Dockerfile
# Description: test image
FROM busybox:latest
MAINTAINER &quot;tanxin &lt;lovegood.xin@gmail.com&gt;&quot;
COPY index.html /data/web/html/
</code></pre>
<h3 id="add">ADD</h3>
<p>两种形式：</p>
<pre><code>ADD [--chown=&lt;user&gt;:&lt;group&gt;] &lt;src&gt;... &lt;dest&gt;
ADD [--chown=&lt;user&gt;:&lt;group&gt;] [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;]
</code></pre>
<p><code>ADD</code>指令类似于<code>COPY</code>指令， <code>ADD</code>支持使用 TAR文件和 URL路径</p>
<ul>
<li>文件操作准则，同<code>COPY</code>，另外：
<ol>
<li>如果&lt;src&gt;为URL且&lt;dest&gt;不以/结尾，则&lt;src&gt;指定的文件将被下载并直接被创建为&lt;dest&gt;；如果&lt;dest&gt;以/结尾，则文件名URL指定的文件将被直接下载，并保存为&lt;dest&gt;/&lt;filename&gt;，注意，URL不能是ftp格式的url</li>
<li>如果&lt;src&gt;是一个本地系统上的压缩格式的tar文件，它将被展开为一个目录，其行为类似于“tar -x”命令，然后，通过URL获取到的tar文件将不会自动展开</li>
<li>如果&lt;src&gt;有多个，或其间接或直接使用了通配符，则&lt;dest&gt;必须是一个以/结尾的目录路径；如果&lt;dest&gt;不以<code>/</code>结尾，则其被视作一个普通文件，&lt;src&gt;的内容将被直接写入到&lt;dest&gt;</li>
</ol>
</li>
</ul>
<h4 id="copy与add的区别">COPY与ADD的区别</h4>
<p><code>ADD</code>支持使用 TAR文件和 URL路径,支持将tar格式的压缩文件解压到指定的目录</p>
<h3 id="label">LABEL</h3>
<pre><code>LABEL &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; ...

LABEL version=&quot;1.0&quot; description=&quot;这是一个github pages&quot; by=&quot;blog&quot;
</code></pre>
<h3 id="workdir">WORKDIR</h3>
<pre><code>WORKDIR /path/to/workdir
</code></pre>
<p>WORKDIR为工作目录，可以出现多次，路径也可以为相对路径，不过，其是相对此前一个 WORKDIR指令指定的路径，还可以用由ENV定义的变量</p>
<h3 id="volume">VOLUME</h3>
<pre><code>VOLUME [&quot;/data&quot;]
</code></pre>
<p>定义卷，只能是docker管理的卷，，VOLUME为容器上的目录，用于在 image中创建一个挂载点目录，以挂载 Docker host上的卷或其它容器上的卷</p>
<h3 id="expose">EXPOSE</h3>
<pre><code>EXPOSE &lt;port&gt; [&lt;port&gt;/&lt;protocol&gt;...]
</code></pre>
<p>暴露指定端口，用于为容器打开指定要监听的端口以实现与外部通信</p>
<p>&lt;protocol&gt;用于指定传输层协议，可为 tcp或udp二者之一，默认为 TCP协议</p>
<p>EXPOSE指令可一次指定多个端口，但是不能指定暴露为宿主机的指定端口，因为指定的宿主机端口可能已经被占用，因此这里使用随机端口</p>
<pre><code>[root@node1 img1]# vim Dockerfile 
EXPOSE 80/tcp
[root@node1 ~]# docker run --name tinyweb1 --rm tinyhttpd:v0.1-6 /bin/httpd -f -h data/web/html

[root@node1 ~]# docker inspect tinyweb1                                                                                                                                         &quot;IPAddress&quot;: &quot;172.17.0.2&quot;,  

[root@node1 ~]# curl 172.17.0.2
&lt;h1&gt;twfr.github.io &lt;/h1&gt;
[root@node1 ~]# docker port tinyweb1   //没有端口信息   即没有正真暴露出来
</code></pre>
<p>启动并暴露端口，注意，启动容器要跟大写P选项-P来暴露</p>
<pre><code>[root@node1 ~]# docker run --name tinyweb1 --rm -P  tinyhttpd:v0.1-6 /bin/httpd -f -h /data/web/html

[root@node1 ~]# curl 172.17.0.2
&lt;h1&gt;twfr.github.io&lt;/h1&gt;
[root@node1 ~]# docker port tinyweb1
80/tcp -&gt; 0.0.0.0:32768
</code></pre>
<h3 id="env">ENV</h3>
<pre><code>ENV &lt;key&gt;=&lt;value&gt; ...
</code></pre>
<p>有些变量在运行为容器时依然有用，因此需要把那些变量在运行为容器时重新定义为一个新的值，如果变量很多，可以放到一个文件中进行定义，使用参数 --env-list(docker run --help )实现，通过文件来加载环境变量</p>
<pre><code>[root@node1 ~]# docker run --name tinyweb1 --rm -P -e WEB_SERVER_PACKAGE=&quot;nginx-1.15-6&quot; tinyhttpd:v0.1-7 printenv
WEB_SERVER_PACKAGE=nginx-1.15-6
</code></pre>
<h3 id="arg">ARG</h3>
<pre><code>ARG &lt;name&gt;[=&lt;default value&gt;]
</code></pre>
<p>ARG用于指定传递给构建运行时的变量</p>
<pre><code>FROM ubuntu
ARG CONT_IMG_VER
ENV CONT_IMG_VER=${CONT_IMG_VER:-v1.0.0}
RUN echo $CONT_IMG_VER
</code></pre>
<pre><code>docker build --build-arg CONT_IMG_VER=v2.0.1 .
</code></pre>
<h3 id="stopsignal">STOPSIGNAL</h3>
<pre><code>STOPSIGNAL signal
</code></pre>
<p>STOPSIGNAL用于设置停止容器所要发送的系统调用信号：<br>
所使用的信号必须是内核系统调用表中的合法的值，如：SIGKILL</p>
<h3 id="user">USER</h3>
<p>USER用于指定运行 image时的或运行 Dockerfile中任何 RUN、CMD或 ENTRYPOINT指令指定的程序时的用户名或 UID ，即改变容器中运行程序的身份<br>
默认情况下， container的运行身份为 root用户<br>
以下形式都是ok的：</p>
<pre><code>USER user
USER user:group
USER uid
USER uid:gid
USER user:gid
USER uid:group
</code></pre>
<h3 id="onbuild">ONBUILD</h3>
<pre><code>ONBUILD &lt;INSTRUCTION&gt;
</code></pre>
<p>当将映像用作另一个构建的基础时，ONBUILD指令会将触发指令添加到映像中，以便稍后执行。触发器将在下游构建的上下文中执行，就像它已被插入到下游Dockerfile中的FROM指令之后一样。</p>
<h3 id="dockerfile原则和建议">dockerfile原则和建议</h3>
<ol>
<li>容器轻量化。从镜像中产生的容器应该尽量轻量化，能在足够短的时间内停止、销毁、重新生成并替换原来的容器。</li>
<li>使用 .gitignore。在大部分情况下，Dockerfile 会和构建所需的文件放在同一个目录中，为了提高构建的性能，应该使用 .gitignore 来过滤掉不需要的文件和目录。</li>
<li>为了减少镜像的大小，减少依赖，仅安装需要的软件包。</li>
<li>一个容器只做一件事。解耦复杂的应用，分成多个容器，而不是所有东西都放在一个容器内运行。如一个 Python Web 应用，可能需要 Server、DB、Cache、MQ、Log 等几个容器。一个更加极端的说法：One process per container。</li>
<li>减少镜像的图层。不要多个 Label、ENV 等标签。</li>
<li>对续行的参数按照字母表排序，特别是使用apt-get install -y安装包的时候。</li>
<li>使用构建缓存。如果不想使用缓存，可以在构建的时候使用参数--no-cache=true来强制重新生成中间镜像。</li>
</ol>
<h2 id="docker生命周期">docker生命周期</h2>
<h3 id="镜像">镜像</h3>
<p>Docker 镜像可以看作是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。镜像不包含任何动态数据，其内容在构建之后也不会被改变。<br>
镜像（Image）就是一堆只读层（read-only layer）的统一视角，这些层是Docker 内部的实现细节，并且能够在主机的文件系统上访问到。统一文件系统 (union file system) 技术能够将不同的层整合成一个文件系统，为这些层提供了一个统一的视角，这样就隐藏了多层的存在，在用户的角度看来，只存在一个文件系统。</p>
<h3 id="容器">容器</h3>
<p>容器 (container) 的定义和镜像 (image) 几乎一模一样，也是一堆层的统一视角，唯一区别在于容器的最上面那一层是可读可写的。<br>
由于容器的定义并没有提及是否要运行容器，所以实际上，容器 = 镜像 + 读写层。</p>
<h3 id="仓库">仓库</h3>
<p>存放镜像的地方</p>
<h2 id="docker架构">docker架构</h2>
<p>核心组件包括：</p>
<ul>
<li>Docker Client<br>
客户端可以构建，运行和停止应用程序，还可以远程与Docker_Host进行交互。最常用的 Docker 客户端就是 docker 命令，我们可以通过 docker 命令很方便地在 host 上构建和运行 docker 容器。</li>
<li>Docker daemon<br>
Docker daemon 是服务器组件，以 Linux 后台服务的方式运行，是 Docker 最核心的后台进程，我们也把它称为守护进程。它负责响应来自 Docker Client 的请求，然后将这些请求翻译成系统调用完成容器管理操作。该进程会在后台启动一个 API Server ，负责接收由 Docker Client 发送的请求，接收到的请求将通过Docker daemon 内部的一个路由分发调度，由具体的函数来执行请求。<br>
docker daemon又可以分为docker server engine和job三部分<br>
ocker Daemon 可以认为是通过 Docker Server 模块接受 Docker Client 的请求，并在 Engine 中处理请求，然后根据请求类型，创建出指定的 Job 并运行。 Docker Daemon 运行在 Docker host 上，负责创建、运行、监控容器，构建、存储镜像。</li>
<li>Docker Image</li>
<li>Docker Registry</li>
<li>Docker Container<br>
容器启动的过程大致如下：</li>
</ul>
<ol>
<li>Docker 客户端执行 docker run 命令</li>
<li>Docker daemon 发现本地没有我们需要的镜像</li>
<li>daemon 从指定的镜像仓库下载镜像</li>
<li>下载完成后，镜像被保存到本地</li>
<li>Docker daemon 启动容器</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ k8s summary]]></title>
        <id>https://twFR.github.io/post/k8s-summary/</id>
        <link href="https://twFR.github.io/post/k8s-summary/">
        </link>
        <updated>2020-03-14T13:57:21.000Z</updated>
        <content type="html"><![CDATA[<p>Kubernetes 提供了一个可弹性运行分布式系统的框架。 Kubernetes 会满足扩展要求、故障转移、部署模式等，提供以下服务</p>
<ul>
<li>服务发现和负载均衡</li>
<li>存储编排</li>
<li>自动部署和回滚</li>
<li>自动完成装箱计算</li>
<li>自我修复</li>
<li>密钥与配置管理</li>
</ul>
<h2 id="组件">组件</h2>
<ul>
<li>
<p>控制面组件（管理面）</p>
<ol>
<li>kube-apiserver  服务器，提供API</li>
<li>kube- controler-manager
<ul>
<li>node controller：负责节点出现故障时进行通知和响应</li>
<li>replication controller：负责为系统中每个副本控制器对象维护正确数量的pod</li>
<li>endpoint controller：填充endpoints对象（即加入service与pod）</li>
<li>service account&amp; token contolers：为新的命名空间传家默认账户和API访问令牌</li>
</ul>
</li>
<li>kube-scheduler 监视新创建  未指定node的pods，选择node让pod运行</li>
<li>etcd  保存集群数据</li>
</ol>
</li>
<li>
<p>Node组件（数据面）</p>
<ol>
<li>kubelet  每个node上的代理。保证containers都运行在pod中。接收一组提供给kubelet的PodSpecs，确保PodSpecs描述的容器处于运行状态且健康。不会管理不是kubernets创建的容器</li>
<li>kube-proxy 每个节点上运行的网络代理，维护节点上的网络规则</li>
</ol>
</li>
<li>
<p>Container Runtime 负责运行容器的软件（docker containers CRI-O）</p>
</li>
<li>
<p>插件（Addons）</p>
<p>插件使用 Kubernetes 资源（<a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/daemonset/">DaemonSet</a>、 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/deployment/">Deployment</a>等）实现集群功能。如DNS，Dashboard</p>
</li>
</ul>
<h2 id="架构">架构</h2>
<h3 id="节点">节点</h3>
<ul>
<li>
<p>可用节点上都包括kubelet，Container Runtime及kube-proxy</p>
</li>
<li>
<p>向API服务器添加节点的方式主要有两种：</p>
<ol>
<li>
<p>节点上的kubelet向控制面执行自注册</p>
<p>当 kubelet 标志 <code>--register-node</code> 为 true（默认）时，它会尝试向 API 服务注册自己</p>
</li>
<li>
<p>手动注册<br>
执行操作后，控制面会检查新的node对象是否合法。 如果节点是健康的（即所有必要的服务都在运行中），则该节点可以用来运行 Pod。 否则，直到该节点变为健康之前，所有的集群活动都会忽略该节点。</p>
</li>
</ol>
</li>
</ul>
<h3 id="控制面节点通信">控制面节点通信</h3>
<ul>
<li>
<p>节点到控制面<br>
Kubernetes 采用的是中心辐射型（Hub-and-Spoke）API 模式。 所有从集群（或所运行的 Pods）发出的 API 调用都终止于 apiserver（其它控制面组件都没有被设计为可暴露远程服务）。 apiserver 被配置为在一个安全的 HTTPS 端口（443）上监听远程连接请求。应该使用集群的公共根证书开通节点，这样它们就能够基于有效的客户端凭据安全地连接 apiserver。<br>
当 Pod 被实例化时，Kubernetes 自动把公共根证书和一个有效的持有者令牌注入到 Pod 里。kubernetes 服务（位于所有名字空间中）配置了一个虚拟 IP 地址，用于（通过 kube-proxy）转发 请求到 apiserver 的 HTTPS 末端。<br>
控制面组件也通过安全端口与集群的 apiserver 通信。<br>
集群节点和节点上运行的 Pod 到控制面的连接的缺省操作模式即是安全的， 能够在不可信的网络或公网上运行。</p>
</li>
<li>
<p>控制面到节点</p>
<ol>
<li>
<p>API服务器到kubelet</p>
<p>从apiserver到kubelet的连接用于：</p>
<ul>
<li>获取pod日志</li>
<li>挂接（通过kubectl）到运行中的pod</li>
<li>通过kubelet的端口转发功能<br>
这些连接终止于 kubelet 的 HTTPS 末端。 默认情况下，apiserver 不检查 kubelet 的服务证书。这使得此类连接容易受到中间人攻击， 在非受信网络或公开网络上运行也是 不安全的。</li>
</ul>
</li>
<li>
<p>apiserver到节点，pod和服务</p>
<p>从 apiserver 到节点、Pod 或服务的连接默认为纯 HTTP 方式，因此既没有认证，也没有加密，这些连接 <strong>目前还不能安全地</strong> 在非受信网络或公共网络上运行。</p>
</li>
</ol>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[k8s Installation and deployment]]></title>
        <id>https://twFR.github.io/post/k8s-installation-and-deployment/</id>
        <link href="https://twFR.github.io/post/k8s-installation-and-deployment/">
        </link>
        <updated>2019-11-19T16:30:24.000Z</updated>
        <content type="html"><![CDATA[<h2 id="准备">准备</h2>
<ul>
<li>Macos/windows系统电脑</li>
<li>vmware虚拟机</li>
<li><a href="http://old-releases.ubuntu.com/releases/18.10/ubuntu-18.10-live-server-amd64.iso">Ubuntu18.10</a></li>
<li><a href="http://m6.pc6.com/xuh6/scrt854.zip">secureCRT</a>（用来管理虚拟机的，比直接用vmware好用多了）</li>
<li><a href="https://download.docker.com/linux/ubuntu/dists/bionic/pool/stable/amd64/docker-ce_18.06.1~ce~3-0~ubuntu_amd64.deb">docker-ce 18.06</a></li>
</ul>
<p>由于我有你们懂得的东西，可以去国外下载对应的镜像组件等，还是比较方便，如果是没有的话，可能还得配置网络源等东西会比较麻烦</p>
<h2 id="安装ubuntu">安装ubuntu</h2>
<p>我是用的mac装的vnware，在虚拟机里面装的ubuntu，还是蛮简单的，注意的是需要至少给虚拟机cpu分配两核，k8s至少要两核才能安装</p>
<h4 id="安装需要的软件">安装需要的软件</h4>
<p>安装一些基础工具</p>
<blockquote>
<p>sudo apt-get update &amp;&amp; apt-get install -y curl telnet wget man \</p>
</blockquote>
<blockquote>
<p>apt-transport-https ca-certificates software-properties-common vim</p>
</blockquote>
<h2 id="安装docker">安装docker</h2>
<ul>
<li>
<p>下载docker18.06的离线安装包  [18.06]</p>
</li>
<li>
<p>scp到自己的虚拟机上面去</p>
<p>先查看自己虚拟机的ip地址：ifconfig<br>
然后 scp docker-ce_18.06.1_ce_3-0_ubuntu_amd64.deb tan@172.16.234.132:/home/tan/package</p>
</li>
</ul>
<p>搞定</p>
<ul>
<li>
<p>离线安装虚拟机</p>
<blockquote>
<p>sudo dpkg -i  docker-ce_18.06.1_ce_3-0_ubuntu_amd64.deb</p>
</blockquote>
<p>我安装遇到了错误 提示我依赖缺失 然后我就安装依赖</p>
<blockquote>
<p>sudo apt-get install -y libltd17</p>
</blockquote>
<p>然后又提示我找不到包，应该就是源文件的问题，更新下源文件</p>
<blockquote>
<p>#仅检查，不更新</p>
<p>sudo apt update</p>
<p>#更新已安装的软件包</p>
<p>sudo apt upsade</p>
</blockquote>
<p>解决之后重新安装docker，搞定</p>
</li>
<li>
<p>允许开机启动docker</p>
<blockquote>
<p>sudo systemctl enable docker</p>
<p>sudo systemctl start docker</p>
</blockquote>
</li>
<li>
<p>启动一个精简的操作系统容器测试</p>
<blockquote>
<p>sudo docker run -ti alpine:latest sh</p>
</blockquote>
</li>
<li>
<p>将当前的普通用户添加到当前的docker用户组里面去</p>
<blockquote>
<p>sudo groupadd docker</p>
<p>sudo usermod -aG docker $USER</p>
</blockquote>
</li>
</ul>
<h2 id="kubernetes安装">kubernetes安装</h2>
<ul>
<li>
<p>免费的阿里云镜像加速器</p>
<p>https://ozcouvlb.mirror.aliyuncs.com</p>
</li>
<li>
<p>配置国内镜像加速器</p>
<blockquote>
<p>vim /etc/docker/daemon.json</p>
<p>#文件里的内容如下：</p>
<p># {</p>
<p>#	&quot;registry-mirrors&quot;:  [https://ozcouvlb.mirror.aliyuncs.com]</p>
<p>#}</p>
</blockquote>
</li>
<li>
<p>重启docker服务</p>
<blockquote>
<p>sudo systemctl daemon-reload</p>
<p>sudo systemctl restart docker</p>
</blockquote>
</li>
<li>
<p>配置并安装k8s源</p>
</li>
<li>
<p>创建配置文件</p>
<blockquote>
<p>sudo vim /etc/apt/sources.list.d/kubernetes.list</p>
<p>#添加以下内容</p>
<p>#deb https://mirrors.ustc.edu.cn/kubernetes/apt kubernets-xenial main</p>
<p>sudo chmod 640 /etc/apt/sources.list.d/kubernetes.list</p>
</blockquote>
</li>
<li>
<p>执行如下命令更新操作系统源</p>
</li>
</ul>
<pre><code>&gt; sudo apt update
</code></pre>
<ul>
<li>
<p>有可能遇到的问题 NO_PUBKEY,解决方法如下：</p>
<blockquote>
<p>#添加认证 一定要用自己的账户执行，不能用root</p>
</blockquote>
<blockquote>
<p>sudo gpg --keyserver keyserver.ubuntu.com --recv-keys BA07F4FB(回显NO_PUBKEY的后8位)</p>
<p>sudo gpg --export --armor BA07F4FB</p>
<p>#将回显的key保存到一个文件里面</p>
<p>vim pubkey</p>
<p>#将ley添加到本地的truested数据库中</p>
<p>sudo apt-key add pubkey</p>
</blockquote>
</li>
<li>
<p>解决后再次更新，完美搞定</p>
</li>
<li>
<p>禁止基础设施</p>
<ul>
<li>关闭防火墙（容器之间通讯不需要这些限制,话说我之前用win一直也都是关闭的）</li>
</ul>
<blockquote>
<p>sudo ufw disable</p>
</blockquote>
<ul>
<li>
<p>关闭swap(k8s不希望使用swap)</p>
<blockquote>
<p>sudo swapoff -a</p>
<p>永久关闭</p>
<p>sudo sed -i 's/.*swap.*/#$/' /etc/fstab</p>
</blockquote>
</li>
<li>
<p>禁止selinux（ubuntu默认安装的安全组件）</p>
<blockquote>
<p>#安装操控selinux的组件</p>
<p>sudo apt install -y selinux-utils</p>
<p>#禁止selinux</p>
<p>setenforce 0</p>
<p>#重启</p>
<p>shutdown -r now</p>
<p>#查看是否关闭</p>
<p>sudo getenforce</p>
</blockquote>
</li>
</ul>
</li>
<li>
<p>k8s系统网络配置</p>
<ol>
<li>配置内核参数，将桥接的IPv4流量传递到iptables的链</li>
</ol>
<p>创建配置文件</p>
<blockquote>
<p>sudo vim /etc/sysctl.d/k8s.conf</p>
</blockquote>
<p>添加如下内容：</p>
<blockquote>
<p>net.bridge.bridge-nf-call-ip6tables = 1</p>
<p>net.bridge.bridge-nf-call-iptables = 1</p>
<p>vm.swappiness = 0</p>
</blockquote>
<ol start="2">
<li>
<p>使配置文件生效</p>
<blockquote>
<p>sudo modprobe br_netfilter</p>
</blockquote>
<blockquote>
<p>sudo sysctl -p /etc/sysctl.d/k8s.conf</p>
</blockquote>
</li>
</ol>
</li>
<li>
<p>安装k8s</p>
<blockquote>
<p>sudo apt update &amp;&amp; apt-get install -y kubelet=1.13.1-00 kubernetes-cni=0.6.0-00 kubeadm=1.13.1-00 kubectl=1.13.1-00</p>
</blockquote>
<ul>
<li>kubelet 永久的后端服务</li>
<li>kubectl 客户端进程，用户和开发者使用kubectl可以运维维护k8s</li>
<li>kubeadm 也是客户端进程，权限很高，相当于管理员，用的很少</li>
</ul>
</li>
<li>
<p>设置开机自启动</p>
<blockquote>
<p>sudo systemctl enable kubelet &amp;&amp; systemctl start kubelet</p>
<p>sudo shutdown -r now</p>
</blockquote>
</li>
<li>
<p>验证k8s</p>
<blockquote>
<p>kubectl get nodes</p>
<p>kubectl version</p>
</blockquote>
</li>
</ul>
<h2 id="创建多节点">创建多节点</h2>
<ul>
<li>
<p>将已经搭建好的环境的虚拟机复制两份出来，搭建一个三节点的集群</p>
<p>将已经搭建好开发环境的虚拟机关机，然后创建完整克隆</p>
</li>
<li>
<p>之后再用ifconfig命令查看新节点的ip，用secureCRT登录节点</p>
</li>
<li>
<p>给node配置hostname</p>
<blockquote>
<p>su</p>
<p>vim /etc/hostname</p>
<p>#分别改为master/node1/node2</p>
</blockquote>
</li>
<li>
<p>配置ip地址</p>
<blockquote>
<p>vim /etc/netplan/50-cloud-init.yaml</p>
</blockquote>
</li>
</ul>
<p>network:</p>
<p>​	 ethernets:</p>
<p>​			ens33:</p>
<p>​					addresses: [172.16.234.134/24]</p>
<p>​					dhcp4: false</p>
<p>​					gateway4: 172.16.234.2</p>
<p>​					nameservers:</p>
<p>​									addresses: [172.16.234.2]</p>
<p>​					optional: true</p>
<p>​			version: 2</p>
<p>按照自己节点的ip配置，也可以自己定为连续的ip，方便操作，dhcp改成false防止每次重启ip变掉</p>
<p>​	&gt; netplan apply</p>
<p>使配置生效</p>
<ul>
<li>
<p>修改hosts文件</p>
<blockquote>
<p>vim /etc/hosts</p>
<p>#输入以下内容</p>
<p>#172.16.234.132 master</p>
<p>#172.16.234.133 node1</p>
<p>#172.16.234.134 node2</p>
</blockquote>
</li>
</ul>
<p>三个节点均需要配置,通过ping来检验是否配置成功</p>
<h2 id="部署k8s集群">部署k8s集群</h2>
<ul>
<li>
<p>---------<font color=red><strong>master节点上配置</strong></font> --------</p>
</li>
<li>
<p>创建k8s的管理工具kubeadm对应的配置文件，候选操作在/home/itcast/working/ 目录下</p>
</li>
<li>
<p>使用kubeadm配置文件，通过在配置文件中指定docker镜像地址部署</p>
<p>生成配置文件</p>
<blockquote>
<p>kubeadm config print init-defaults ClusterConfiguration &gt; kubeadm.conf</p>
</blockquote>
</li>
<li>
<p>修改配置文件里面的下面项</p>
<blockquote>
<p>vim kubeadm.conf</p>
<p>#修改k8s版本号为v1.13.1</p>
<p>kubernetesVersion: v1.13.1</p>
<p>#修改hostname为master</p>
<p>name: master</p>
<p>#修改kubeadm.conf中的API服务器地址</p>
<p>localAPIEndpoint:</p>
<p>​    advertiseAddress: 172.16.234.132    # master的IP</p>
<p>​    bindPort：6443</p>
<p>#配置子网网络</p>
<p>networking:</p>
<p>​    dnsDomian: cluster.local</p>
<p>​    podSubnet: &quot;10.244.0.0/16&quot;         #  k8s内部pod网络,官方推荐</p>
<p>​    servicesSubnet: 10.96.0.0/12    # k8s服务网络,官方推荐</p>
<p>scheduler: {}</p>
</blockquote>
</li>
<li>
<p>拉取k8s必备的模块镜像</p>
<blockquote>
<p>#查看需要哪些镜像文件需要拉取</p>
<p>kubeadm config images list --config kubeadm.conf</p>
<p>#k8s.gcr.io/kube-apiserver:v1.13.1.                   对外端口，提供入口让外部访问集群<br>
#k8s.gcr.io/kube-controller-manager:v1.13.1     内部管理器<br>
#k8s.gcr.io/kube-scheduler:v1.13.1                   内部任务调度器<br>
#k8s.gcr.io/kube-proxy:v1.13.1                         负载均衡<br>
#k8s.gcr.io/pause:3.1                                     业务容器共享Pause容器的网络栈和Volume挂载卷，因此他们之间通信和数据交换更为高效<br>
#k8s.gcr.io/etcd:3.2.24                                  数据一致性<br>
#k8s.gcr.io/coredns:1.2.6</p>
<p>#拉取全部当前版本k8s关联的镜像</p>
<p>kubeadm config images pull --config ./kubeadm.conf</p>
<p>#如果无法下载，只能去docker.io仓库手动拉镜像然后改tag（或者registry.cn-hangzhou.aliyuncs.com/google_containers）</p>
<p>docker pull mirrorgooglecontainers/kube-apiserver:v1.13.1</p>
<p>docker tag mirrorgooglecontainers/kube-apiserver:v1.13.1 k8s.gcr.io/kube-apiserver:v1.13.1 #打tag，和需要的镜像名保持一致</p>
<p>docker rmi mirrorgooglecontainers/kube-apiserver:v1.13.1    #删除掉多余的镜像</p>
<p>#其他所有镜像类似,k8s.gcr.io/coredns:1.2.6特例</p>
<p>docker pull coredns/coredns:1.1.3</p>
<p>root@tan:/home/tan/package# docker images<br>
REPOSITORY                           TAG                 IMAGE ID            CREATED             SIZE<br>
k8s.gcr.io/kube-proxy                v1.13.1             fdb321fd30a0        11 months ago       80.2MB<br>
k8s.gcr.io/kube-apiserver            v1.13.1             40a63db91ef8        11 months ago       181MB<br>
k8s.gcr.io/kube-controller-manager   v1.13.1             26e6f1db2a52        11 months ago       146MB<br>
k8s.gcr.io/kube-scheduler            v1.13.1             ab81d7360408        11 months ago       79.6MB<br>
k8s.gcr.io/etcd                      3.2.24              3cab8e1b9802        14 months ago       220MB<br>
k8s.gcr.io/coredns                   1.2.6               b3b94275d97c        18 months ago       45.6MB<br>
k8s.gcr.io/pause                     3.1                 da86e6ba6ca1        23 months ago       742kB</p>
</blockquote>
</li>
<li>
<p>初始化k8s环境</p>
<blockquote>
<p>sudo kubeadm init --config ./kubeadm.conf</p>
</blockquote>
</li>
</ul>
<p>回显如下：</p>
<pre><code>	 &gt; Your Kubernetes master has initialized successfully!
	 &gt;
	 &gt; To start using your cluster, you need to run the following as a regular user:
	 &gt;
	 &gt; ​    mkdir -p $HOME/.kube
	 &gt;
	 &gt; ​	sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
	 &gt;
	 &gt; ​	sudo chown $(id -u):$(id -g) $HOME/.kube/config
	 &gt;
	 &gt; You should now deploy a pod network to the cluster.
	 &gt; Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:
	 &gt;   https://kubernetes.io/docs/concepts/cluster-administration/addons/
	 &gt;
	 &gt; You can now join any number of machines by running the following on each node
	 &gt; as root:
	 &gt;
	 &gt;   kubeadm join 172.16.234.132:6443 --token abcdef.0123456789abcdef --discovery-token-ca-cert-hash sha256:ebc50ff8588c35917f9c6f84f2bd8048352b82bfb9ef06cf5b63934cb9862f49
</code></pre>
<p>根据提示，做如下操作</p>
<blockquote>
<p>#master节点基本文件夹配置</p>
</blockquote>
<blockquote>
<p>mkdir -p $HOME/.kube</p>
<p>sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</p>
<p>sudo chown <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>(</mo><mi>i</mi><mi>d</mi><mo>−</mo><mi>u</mi><mo>)</mo><mo>:</mo></mrow><annotation encoding="application/x-tex">(id -u):</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault">i</span><span class="mord mathdefault">d</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">u</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span></span></span></span>(id -g) $HOME/.kube/config</p>
</blockquote>
<p>同时，如果node节点想要加入master集群，需要执行以下命令</p>
<blockquote>
<p>kubeadm join 172.16.234.132:6443 --token abcdef.0123456789abcdef --discovery-token-ca-cert-hash sha256:ebc50ff8588c35917f9c6f84f2bd8048352b82bfb9ef06cf5b63934cb9862f49</p>
</blockquote>
<ul>
<li>
<p>启动k8s</p>
<blockquote>
<p>sudo systemctl enable kubelet</p>
<p>sudo systemctl start kubelet</p>
</blockquote>
</li>
<li>
<p>验证k8s启动结果</p>
<blockquote>
<p>kubectl get node</p>
</blockquote>
</li>
</ul>
<p>如果有问题，可以参考这个 <a href="https://stackoverflow.com/questions/52720380/kubernetes-api-server-is-not-starting-on-a-single-kubeadm-cluster">拉取最新版本</a>然后重新来一遍，我就是这个花了一下午（微笑脸）</p>
<p>未完待续。。。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[fibobacci]]></title>
        <id>https://twFR.github.io/post/fibobacci/</id>
        <link href="https://twFR.github.io/post/fibobacci/">
        </link>
        <updated>2019-11-18T15:49:09.000Z</updated>
        <content type="html"><![CDATA[<p>今天简单做一个题，这个点了，太累了，打卡滴</p>
<h2 id="需求">需求</h2>
<p>给一个数N，看能通过多少步N+1或者N-1使它成为fibobacci数<br>
0&lt; N &lt;1000000<br>
fibobacci都清楚 0 1 1 2 3 5 8 13 ... 不赘述</p>
<h2 id="示例">示例</h2>
<p>输入：</p>
<blockquote>
<p>5<br>
15</p>
</blockquote>
<p>输出：</p>
<blockquote>
<p>0<br>
2</p>
</blockquote>
<h2 id="解题思路">解题思路</h2>
<p>这个就很简单，不用说了<br>
看我极简代码风格，哈哈哈😂</p>
<h2 id="极简代码">极简代码</h2>
<pre><code>package main

import &quot;fmt&quot;

func main() {
	var number int
	for {
		if num, err := fmt.Scanf(&quot;%d&quot;, &amp;number); num != 1 || err != nil {
			return
		}
		begin, next := 0, 1
		for begin+next &lt; number {
			begin, next = next, begin+next
		}
		if number-next &lt; begin+next-number {
			fmt.Println(number - next)
		} else {
			fmt.Println(begin + next - number)
		}
	}
}

</code></pre>
<p>当然不推荐，容易被打死</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[binary search]]></title>
        <id>https://twFR.github.io/post/binary-search/</id>
        <link href="https://twFR.github.io/post/binary-search/">
        </link>
        <updated>2019-11-17T12:43:15.000Z</updated>
        <content type="html"><![CDATA[<h2 id="需求">需求</h2>
<p>小Q的父母要出差N天，走之前给小Q留下了M块巧克力。小Q决定每天吃的巧克力数量不少于前一天的一半，但是他又不想在父母回来之前把巧克力吃完，请问他<font color=red>第</font>一天<font color=red>最多</font>能吃多少块蛋糕<br>
N&lt;=50000,N&lt;M&lt;100000</p>
<h2 id="示例">示例</h2>
<p>输入：</p>
<blockquote>
<p>3 7<br>
4 7</p>
</blockquote>
<p>输出：</p>
<blockquote>
<p>4<br>
3</p>
</blockquote>
<h2 id="解题思路">解题思路</h2>
<ul>
<li>本题可以想成，我从1～M块巧克力中选出一块来，这块巧克力就是我第一天最多能吃的巧克力</li>
<li>那这个选出来的有什么条件需要满足呢：要满足我选出来的这个是第一天最多能吃的，那么就是最后几天都要吃最少的，但又要满足不少于前一天的一半，所以就是刚好吃前一天的一半。注意的是，这里要吃就是一整块，不存在是吃几分之一块，强迫症很舒服</li>
<li>那就是我用二分查找法去选一个巧克力数出来，去看是否满足条件</li>
<li>这个条件呢就是你每天吃的加起来刚好或者说小于你的总巧克力数，不能饿死嘛，保证每天都有吃的</li>
</ul>
<h2 id="代码实现">代码实现</h2>
<pre><code>package main

import (
	&quot;fmt&quot;
	&quot;math&quot;
	&quot;os&quot;
)

// 出差天数
var N int

// 巧克力个数
var M int

func main() {
	for {
		num, err := fmt.Scanf(&quot;%d %d&quot;, &amp;N, &amp;M)
		if num != 2 || err != nil {
			fmt.Println(err)
			os.Exit(1)
		}
		search()
	}
}

// 假如第一天吃n个,计算总共吃了多少个
func sum(n int) (m int) {
	for i := 0; i &lt; N; i++ {
		m =m + n
		n = int(math.Ceil(float64 (n) / 2))
	}
	return m
}

// 二分查找满足的条件
func search() {
	begin := 1
	end := M
	mid := 0
	if N == 1 {
		fmt.Println(M)
		return
	}
	for i := 0; i &lt; M; i++ {

		if begin &gt; end {
			break
		}
		// 向上取整，要吃就要吃一整个
		mid = int(math.Ceil(float64(end+begin) / 2))
		if sum(mid) == M {
			fmt.Println(mid)
			return
		}
		if sum(mid) &lt; M {
			// 取等于是因为防止没有正好吃完的情况，需要取mid的值
			begin = mid
		} else {
			end = mid - 1
		}
	}
	// 这是有剩余巧克力的情况
	fmt.Println(mid)
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Insert sort]]></title>
        <id>https://twFR.github.io/post/insert-sort/</id>
        <link href="https://twFR.github.io/post/insert-sort/">
        </link>
        <updated>2019-11-15T15:36:02.000Z</updated>
        <content type="html"><![CDATA[<h2 id="需求">需求</h2>
<p>输入n个数字，（第一行数字表示将要输入数字的个数）<br>
按从小到大的顺序排序后一行输出</p>
<h2 id="示例">示例</h2>
<p>输入：</p>
<blockquote>
<p>5<br>
12<br>
45<br>
2<br>
14<br>
1</p>
</blockquote>
<p>输出：</p>
<blockquote>
<p>1 2 12 14 45</p>
</blockquote>
<h2 id="解题思路">解题思路</h2>
<p>今天使用插入排序来解决这个问题</p>
<ul>
<li>循环需要排序的数组</li>
<li>从第二个数字开始，和前一个比较，如果比前一个小，就说明这第i个数字n需要重新排序</li>
<li>将这个数字和前面的所有数字比较，当n比第j个数字位置小的时候（j&lt;i），则说明这个j位置就是n需要插入的位置</li>
<li>将j位置到i-1位置的数字全部顺序向后移动一个位置，即将【i-1】赋给【i】，最后将最开始的【i】赋给【j】</li>
<li>循环完数组则排序完毕，over</li>
</ul>
<pre><code>func insertSort(disorderNumber []int) []int {
	for i := 1; i &lt; len(disorderNumber); i++ {
		if disorderNumber[i] &lt; disorderNumber[i-1] {
			for j := 0; j &lt; i; j++ {
				if disorderNumber[j] &gt; disorderNumber[i] {
					// 插入位置
					temp := disorderNumber[i]
					// 将插入位置后面的数到需要插入的数整体后移一位
					for k := i; k &gt; j; k-- {
						disorderNumber[k] = disorderNumber[k-1]
					}
					disorderNumber[j] = temp
				}
				// 如果找到插入位置，则不需要再向后面循环
				break
			}
		}
	}
	return disorderNumber
}
</code></pre>
<h2 id="完整代码">完整代码</h2>
<pre><code>package main

import (
	&quot;fmt&quot;
	&quot;os&quot;
	&quot;strconv&quot;
)

func main() {
	var num int
	n, err := fmt.Scanf(&quot;%d&quot;, &amp;num)
	if n != 1 || err != nil {
		os.Exit(1)
	}
	disorderNumber := make([]int, num)
	for i := 0; i &lt; num; i++ {
		n, err := fmt.Scanf(&quot;%d&quot;, &amp;disorderNumber[i])
		if n != 1 || err != nil {
			fmt.Println(n,err)
			os.Exit(1)
		}
	}
	orderNumber := insertSort(disorderNumber)
	for i := 0; i &lt; len(orderNumber); i++ {
		fmt.Print(strconv.Itoa(orderNumber[i]) + &quot; &quot;)
	}
}

func insertSort(disorderNumber []int) []int {
	for i := 1; i &lt; len(disorderNumber); i++ {
		if disorderNumber[i] &lt; disorderNumber[i-1] {
			for j := 0; j &lt; i; j++ {
				if disorderNumber[j] &gt; disorderNumber[i] {
					// 插入位置
					temp := disorderNumber[i]
					// 将插入位置后面的数到需要插入的数整体后移一位
					for k := i; k &gt; j; k-- {
						disorderNumber[k] = disorderNumber[k-1]
					}
					disorderNumber[j] = temp
				}
				// 如果找到插入位置，则不需要再向后面循环
				break
			}
		}
	}
	return disorderNumber
}
</code></pre>
]]></content>
    </entry>
</feed>