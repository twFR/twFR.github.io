<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://twFR.github.io</id>
    <title>🌟谭先生✨</title>
    <updated>2021-01-19T13:00:17.578Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://twFR.github.io"/>
    <link rel="self" href="https://twFR.github.io/atom.xml"/>
    <subtitle>敲不出代码的程序猿的🏠</subtitle>
    <logo>https://twFR.github.io/images/avatar.png</logo>
    <icon>https://twFR.github.io/favicon.ico</icon>
    <rights>All rights reserved 2021, 🌟谭先生✨</rights>
    <entry>
        <title type="html"><![CDATA[mysql]]></title>
        <id>https://twFR.github.io/post/mysql/</id>
        <link href="https://twFR.github.io/post/mysql/">
        </link>
        <updated>2021-01-19T06:43:23.000Z</updated>
        <content type="html"><![CDATA[<h2 id="sql执行过程">sql执行过程</h2>
<p>大体来说，mysql可以分为server层和引擎层两部分</p>
<p>Server层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖MySQL的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等</p>
<p>存储引擎层负责数据的存储和提取，支持 InnoDB、MyISAM、Memory 等多个存储引擎，现在的默认引擎是<font color=red>InnoDB</font></p>
<p>执行sql的大致流程如下：</p>
<ol>
<li>远程或者本地连接上数据后，执行sql命令</li>
<li>sql命令发送到服务端，首先查询缓存（在8.0取消了缓存机制），缓存以key-value形式存储在内存中，key是查询语句，value是查询结果。缓存中如果找到对应的key，就直接返回结果</li>
<li>如果找不到缓存，就要真正执行sql了。mysql的<code>分析器</code>先做<code>词法分析</code>，把sql里面的字符串是什么，代表什么识别出来；然后做<code>语法分析</code>,判断输入的sql语句是否满足语法（做什么）</li>
<li>分析完之后，mysql就会知道要做什么了，然后<code>优化器</code>开始工作。如果有索引，优化器会决定使用哪个索引，或者多表连接的时候，决定各个表的连接顺序（怎么做）</li>
<li>优化完毕，开始执行语句之前，会先判断是否有权限去操作表，如果有的话，就打开表继续执行，<code>执行器</code>根据表引擎定义，使用这个引擎提供的接口，获取数据将结果返回给客户端</li>
</ol>
<h2 id="mysql-索引">mysql 索引</h2>
<p>索引的目的是为了加快查询速度，是存储引擎用于快速找到记录的一种数据结构。</p>
<h3 id="索引分类">索引分类</h3>
<ul>
<li>普通索引index :加速查找</li>
<li>唯一索引
<ul>
<li>主键索引：primary key ：加速查找+约束（不为空且唯一）</li>
<li>唯一索引：unique：加速查找+约束 （唯一）</li>
</ul>
</li>
<li>联合索引
<ul>
<li>primary key(id,name):联合主键索引</li>
<li>unique(id,name):联合唯一索引</li>
<li>index(id,name):联合普通索引</li>
</ul>
</li>
<li>全文索引fulltext :用于搜索很长一篇文章的时候，效果最好。</li>
<li>空间索引spatial :了解就好，几乎不用</li>
</ul>
<h3 id="索引算法">索引算法</h3>
<ul>
<li>
<p>哈希索引 （查询单条快，范围查询慢）<br>
hash索引结构的特殊性，其检索效率非常高，索引的检索可以一次定位，不像B-Tree索引需要从根节点到枝节点，最后才能访问到页节点这样多次的IO访问，所以Hash索引的查询效率要远高于B-Tree索引<br>
但hash索引由于起特殊性也带来了很多限制和弊端：</p>
<ol>
<li>hash索引只支持等值比较查询，包括＝、 IN 、&lt;=&gt;  (注意&lt;&gt;和＜＝＞是不同的操作，不支持任何范围查询，如&gt; &lt; like等，因为经过相应的Hash算法处理之后的Hash值的大小关系，并不能保证和Hash运算前完全一样</li>
<li>Hash索引无法被用来避免数据的排序操作</li>
<li>Hash索引不能利用部分索引键查询，对于组合索引，Hash索引在计算Hash值的时候是组合索引键合并后再一起计算Hash值，而不是单独计算Hash值，所以通过组合索引的前面一个或几个索引键进行查询的时候，Hash索引也无法被利用</li>
<li>Hash索引在任何时候都不能避免表扫描。Hash索引是将索引键通过Hash运算之后，将 Hash运算结果的Hash值和所对应的行指针信息存放于一个Hash表中，于不同索引键存在相同Hash值，所以即使取满足某个Hash键值的数据的记录条数，也无法从Hash索引中直接完成查询，还是要通过访问表中的实际数据进行相应的比较，并得到相应的结果。</li>
<li>hash索引遇到大量Hash值相等的情况后性能并不一定就会比BTree索引高。对于选择性比较低的索引键，如果创建Hash索引，那么将会存在大量记录指针信息存于同一个Hash值相关联。这样要定位某一条记录时就会非常麻烦，会浪费多次表数据的访问，而造成整体性能低下</li>
</ol>
</li>
<li>
<p>BTree索引（b+树，层数越多，数据量指数级增长，innodb默认支持）<br>
磁盘io预读策略，当一次io的时候，不光把当前磁盘地址的数据，而是把相邻的数据也读到内存缓冲区内，BTree索引就用到了这个策略</p>
<p><a href="www.liuzk.com/wp-content/uploads/2019/11/7.jpg">B+数图</a></p>
<p>B+树是一个从顶层向下查找的树，非叶子节点只存储指引搜索方向的数据项，叶子结点存储真实的数据</p>
<ol>
<li>如上图，根节点也就是页1常驻内存，此时不需要读取磁盘数据，直接从内存中读取</li>
<li>如果现在要查找小于18的数据或者范围值，首先找到id=1的键值，然后根据p1指针就定位到了页2</li>
<li>拿着p1指针去磁盘读取页2后将页2放在内存中，然后进行超找，可以找到键值1，再拿到p1指针，定位到页1</li>
<li>同样页1不存在内存中，根据p1去磁盘读取页1到内存中。此时，因为已经在数据页即叶子结点了，页中数据都是链表进行连接的，而且键值顺序存放，此时用二分查找定位到1，所以只需要根据1往后面遍历匹配满足条件的数据就好了。一直到键值5的数据，页1就没有数据了，拿着页1的p指针去读页2的数据</li>
<li>同样读到内存后，重复4的操作，直到不满足。</li>
<li>最后满足的数据为(1,aa) (3,ki)...(17,mn) 9个数据</li>
</ol>
<p>B+数性质：</p>
<ul>
<li>索引的字段尽量的小：通过上述的流程可以看出，IO次数取决于b+数的高度h，假设当前数据表的数据为N，每个磁盘块的数据项的数量是m，则有h=㏒(m+1)N，当数据量N一定的情况下，m越大，h越小；而m = 磁盘块的大小 / 数据项的大小，磁盘块的大小也就是一个数据页的大小，是固定的，如果数据项占的空间越小，数据项的数量越多，树的高度越低。这就是为什么每个数据项，即索引字段要尽量的小，比如int占4字节，要比bigint8字节少一半。这也是为什么b+树要求把真实的数据放到叶子节点而不是内层节点，一旦放到内层节点，磁盘块的数据项会大幅度下降，导致树增高。当数据项等于1时将会退化成线性表。</li>
<li>索引的最左匹配特性：当B+树是符合数据结构时，B+树是按照从左到右的顺序简历搜索树的，比如（name，age，sex），B+树会先通过name来比较后才能根据age，sex比较，检索到数据。如果name缺失，那B+树就不知道如何下手了，此时就不会用此索引了，必须按从左到右顺序来进行匹配，这就是最左匹配原则</li>
</ul>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Time Format]]></title>
        <id>https://twFR.github.io/post/time-format/</id>
        <link href="https://twFR.github.io/post/time-format/">
        </link>
        <updated>2021-01-16T06:28:09.000Z</updated>
        <content type="html"><![CDATA[<p>昨天听高人说golang的time format很有意思，之前没有用到过，专门了解了一下<br>
当我试着随便如下打印当前时间：</p>
<pre><code>fmt.Println(time.Now().Format(&quot;2021年1月16日&quot; ))
</code></pre>
<p>output:</p>
<pre><code>16161年1月16日
</code></pre>
<p>大惑不解，googel了一下，说是一定要用固定的时间去格式化，Go的蛋辰，果然仪式感还是很重要的，如下</p>
<pre><code>fmt.Println(time.Now().Format(&quot;2006年1月2日 15:04:05&quot; ))
fmt.Println(time.Now().Format(&quot;2006年1月2日&quot; ))
</code></pre>
<p>output:</p>
<pre><code>2021年1月16日 18:37:18
2021年1月16日
</code></pre>
<p>稍微看下源码<br>
在AppendFormat方法里调用nextStdChunk方法，确实是用循环去对固定的时间检索：</p>
<pre><code>// nextStdChunk finds the first occurrence of a std string in
// layout and returns the text before, the std string, and the text after.
func nextStdChunk(layout string) (prefix string, std int, suffix string) {
	for i := 0; i &lt; len(layout); i++ {
		switch c := int(layout[i]); c {
		case 'J': // January, Jan
			if len(layout) &gt;= i+3 &amp;&amp; layout[i:i+3] == &quot;Jan&quot; {
				if len(layout) &gt;= i+7 &amp;&amp; layout[i:i+7] == &quot;January&quot; {
					return layout[0:i], stdLongMonth, layout[i+7:]
				}
				if !startsWithLowerCase(layout[i+3:]) {
					return layout[0:i], stdMonth, layout[i+3:]
				}
			}

		case 'M': // Monday, Mon, MST
			if len(layout) &gt;= i+3 {
				if layout[i:i+3] == &quot;Mon&quot; {
					if len(layout) &gt;= i+6 &amp;&amp; layout[i:i+6] == &quot;Monday&quot; {
						return layout[0:i], stdLongWeekDay, layout[i+6:]
					}
					if !startsWithLowerCase(layout[i+3:]) {
						return layout[0:i], stdWeekDay, layout[i+3:]
					}
				}
				if layout[i:i+3] == &quot;MST&quot; {
					return layout[0:i], stdTZ, layout[i+3:]
				}
			}

		case '0': // 01, 02, 03, 04, 05, 06, 002
			if len(layout) &gt;= i+2 &amp;&amp; '1' &lt;= layout[i+1] &amp;&amp; layout[i+1] &lt;= '6' {
				return layout[0:i], std0x[layout[i+1]-'1'], layout[i+2:]
			}
			if len(layout) &gt;= i+3 &amp;&amp; layout[i+1] == '0' &amp;&amp; layout[i+2] == '2' {
				return layout[0:i], stdZeroYearDay, layout[i+3:]
			}

		case '1': // 15, 1
			if len(layout) &gt;= i+2 &amp;&amp; layout[i+1] == '5' {
				return layout[0:i], stdHour, layout[i+2:]
			}
			return layout[0:i], stdNumMonth, layout[i+1:]

		case '2': // 2006, 2
			if len(layout) &gt;= i+4 &amp;&amp; layout[i:i+4] == &quot;2006&quot; {
				return layout[0:i], stdLongYear, layout[i+4:]
			}
			return layout[0:i], stdDay, layout[i+1:]

		case '_': // _2, _2006, __2
			if len(layout) &gt;= i+2 &amp;&amp; layout[i+1] == '2' {
				//_2006 is really a literal _, followed by stdLongYear
				if len(layout) &gt;= i+5 &amp;&amp; layout[i+1:i+5] == &quot;2006&quot; {
					return layout[0 : i+1], stdLongYear, layout[i+5:]
				}
				return layout[0:i], stdUnderDay, layout[i+2:]
			}
			if len(layout) &gt;= i+3 &amp;&amp; layout[i+1] == '_' &amp;&amp; layout[i+2] == '2' {
				return layout[0:i], stdUnderYearDay, layout[i+3:]
			}

		case '3':
			return layout[0:i], stdHour12, layout[i+1:]

		case '4':
			return layout[0:i], stdMinute, layout[i+1:]

		case '5':
			return layout[0:i], stdSecond, layout[i+1:]

		case 'P': // PM
			if len(layout) &gt;= i+2 &amp;&amp; layout[i+1] == 'M' {
				return layout[0:i], stdPM, layout[i+2:]
			}

		case 'p': // pm
			if len(layout) &gt;= i+2 &amp;&amp; layout[i+1] == 'm' {
				return layout[0:i], stdpm, layout[i+2:]
			}

		case '-': // -070000, -07:00:00, -0700, -07:00, -07
			if len(layout) &gt;= i+7 &amp;&amp; layout[i:i+7] == &quot;-070000&quot; {
				return layout[0:i], stdNumSecondsTz, layout[i+7:]
			}
			if len(layout) &gt;= i+9 &amp;&amp; layout[i:i+9] == &quot;-07:00:00&quot; {
				return layout[0:i], stdNumColonSecondsTZ, layout[i+9:]
			}
			if len(layout) &gt;= i+5 &amp;&amp; layout[i:i+5] == &quot;-0700&quot; {
				return layout[0:i], stdNumTZ, layout[i+5:]
			}
			if len(layout) &gt;= i+6 &amp;&amp; layout[i:i+6] == &quot;-07:00&quot; {
				return layout[0:i], stdNumColonTZ, layout[i+6:]
			}
			if len(layout) &gt;= i+3 &amp;&amp; layout[i:i+3] == &quot;-07&quot; {
				return layout[0:i], stdNumShortTZ, layout[i+3:]
			}

		case 'Z': // Z070000, Z07:00:00, Z0700, Z07:00,
			if len(layout) &gt;= i+7 &amp;&amp; layout[i:i+7] == &quot;Z070000&quot; {
				return layout[0:i], stdISO8601SecondsTZ, layout[i+7:]
			}
			if len(layout) &gt;= i+9 &amp;&amp; layout[i:i+9] == &quot;Z07:00:00&quot; {
				return layout[0:i], stdISO8601ColonSecondsTZ, layout[i+9:]
			}
			if len(layout) &gt;= i+5 &amp;&amp; layout[i:i+5] == &quot;Z0700&quot; {
				return layout[0:i], stdISO8601TZ, layout[i+5:]
			}
			if len(layout) &gt;= i+6 &amp;&amp; layout[i:i+6] == &quot;Z07:00&quot; {
				return layout[0:i], stdISO8601ColonTZ, layout[i+6:]
			}
			if len(layout) &gt;= i+3 &amp;&amp; layout[i:i+3] == &quot;Z07&quot; {
				return layout[0:i], stdISO8601ShortTZ, layout[i+3:]
			}

		case '.': // .000 or .999 - repeated digits for fractional seconds.
			if i+1 &lt; len(layout) &amp;&amp; (layout[i+1] == '0' || layout[i+1] == '9') {
				ch := layout[i+1]
				j := i + 1
				for j &lt; len(layout) &amp;&amp; layout[j] == ch {
					j++
				}
				// String of digits must end here - only fractional second is all digits.
				if !isDigit(layout, j) {
					std := stdFracSecond0
					if layout[i+1] == '9' {
						std = stdFracSecond9
					}
					std |= (j - (i + 1)) &lt;&lt; stdArgShift
					return layout[0:i], std, layout[j:]
				}
			}
		}
	}
	return layout, 0, &quot;&quot;
}
</code></pre>
<p>记时间方法也挺简单 6(年)1(月)2(日)3(时)4(分)5(秒),严重怀疑只是为了简单。 看来我还是太单纯</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[operator summary]]></title>
        <id>https://twFR.github.io/post/operator-summary/</id>
        <link href="https://twFR.github.io/post/operator-summary/">
        </link>
        <updated>2020-10-21T01:45:45.000Z</updated>
        <content type="html"><![CDATA[<h2 id="概念">概念</h2>
<p>Operator 是一组软件，可用于降低运行其他软件的操作复杂程度，从技术上讲，Operator 是一种打包、部署和管理 Kubernetes 应用程序的方法。<br>
operator可以：</p>
<ul>
<li>重复安装和升级</li>
<li>持续对每个系统组件执行运行状况检查</li>
<li>汇总现场工程师了解的情况并将其传输给所有用户，而非一两个用户<br>
operator与servie broker相比：</li>
<li>Service Broker 朝着实现应用程序的编程式发现和部署的目标前进了一步。但它并非一个长时间运行的进程，所以无法执行第 2 天操作，如升级、故障转移或扩展。它在安装时提供对可调参数的自定义和参数化，而 Operator 则可持续监控集群的当前状态。非集群服务仍非常适合于 Service Broker，但也存在合适于这些服务的 Operator</li>
</ul>
<h2 id="operator-framework">operator framework</h2>
<ul>
<li><strong>operator SDK</strong>   辅助开发者根据自身专业知识，引导，构建，测试和包装其operator</li>
<li><strong>Operator Lifecycle</strong> Manager 控制集群中operator的安装，升级和基于角色的访问控制（RBAC）</li>
<li><strong>Operator Registry</strong> 存储CSV和CRD以便在集群中创建，并存储有关软件包和频道的operator元数据</li>
<li>OperatorHub</li>
<li>Operator Metering</li>
</ul>
<h3 id="常用术语">常用术语</h3>
<ul>
<li><strong>bundle</strong> 在bndle fromat中，bundle是CSV，manifests以及metadata的集合</li>
<li><strong>CatalogSource</strong> 定义应用程序的CSV CRD和软件包仓库</li>
<li><strong>channel</strong>  channel为 Operator 定义更新流，用于为订阅者推出更新。channel head指向该channel的最新版本。例如，stable channel中会包含 Operator 的所有稳定版本，按由旧到新的顺序排列</li>
<li><strong>CSV</strong> CSV是利用operator的manifest创建的YAML清单，可辅助olm在集群中运行operator。附带的manifest还可用于在用户界面填充徽标 描述和版本信息。此外，CSV 还是运行 Operator 所需的技术信息来源，类似于其需要的 RBAC 规则及其管理或依赖的自定义资源 (CR)。</li>
<li><strong>InstallPlan</strong> ip是一个列出了为自动安装或升级 CSV 而需创建的资源的计算列表</li>
<li><strong>OperatorGroup</strong> og将部署在同一命名空间中的所有 Operator 配置为og对象，以便在一系列命名空间或集群范围内监视其 CR。</li>
<li><strong>Subscription</strong> sub通过跟踪软件包中的频道来保持 CSV 最新。</li>
</ul>
<h3 id="operator-lifecycle-manager">Operator Lifecycle Manager</h3>
<p>olm可帮助用户安装 更新和管理所有operator的生命周期</p>
<ol>
<li>olm资源
<ul>
<li>由olm oerator和catalog oerator管理的CRD
<ul>
<li><strong>CSV</strong> OLM 需要与 Operator 相关的元数据，以确保它可以在集群中安全运行，并在发布新版 Operator 时提供有关如何应用更新的信息。此外，CSV 还是运行 Operator 所需的技术信息来源，例如其管理或依赖的自定义资源 (CR)、RBAC 规则、集群要求和安装策略。此信息告诉 OLM 如何创建所需资源并将 Operator 设置为 Deployment。</li>
<li><strong>catalogsource</strong> CatalogSource 代表 OLM 可查询的元数据存储，以发现和安装 Operator 及其依赖项。<br>
catsrc有三种sourceTypes：<br>
- 带有<code>image</code>引用的<code>grpc</code>：OLM拉取镜像并运行pod<br>
- 带有<code>address</code>引用的<code>grpc</code>:OLM会尝试给定地址的gRPC API<br>
- <code>internal</code>或<code>configmap</code>: OLM 解析 ConfigMap 数据，并运行一个可以为其提供 gRPC API 的 pod</li>
<li><strong>Subscription</strong> 将 Operator 与 CatalogSource 关联的自定义资源,Subscription 描述了要订阅 Operator 软件包的哪个频道，以及是自动还是手动执行更新。如果设置为自动，Subscription 会确保由 OLM 管理并升级 Operator，以确保集群中始终运行最新版本。</li>
<li><strong>InstallPlan</strong> ip定义了要创建的一组资源，用于安装或升级到 CSV 定义的 ClusterService 的特定版本。</li>
<li><strong>OperatorGroup</strong> 为 OLM 安装的 Operator 提供多租户配置。OperatorGroup 选择目标命名空间，在其中为其成员 Operator 生成所需的 RBAC 访问权限。</li>
</ul>
</li>
</ul>
</li>
<li>olm架构<br>
由olm operator和catalog operator管理的CRD：csv，ip，catsrc，sub，og<br>
由olm operator创建的资源：sa，clusterRoles，clusterRoleBindings<br>
由catalog operator创建的资源 CRD CSV
<ul>
<li><strong>Catalog Operator</strong><br>
Catalog Operator 负责解析和安装 CSV 及其指定的所需资源。另外还负责监视频道中的 CatalogSource 中是否有软件包更新，并将其升级（可选择自动）至最新可用版本。<br>
用户可创建 Subscription 资源，该资源将配置所需软件包、频道和 CatalogSource，以便从中拉取更新。找到更新后，便会代表用户将适当 InstallPlan 写入命名空间。<br>
catalog operator工作流：
<ol>
<li>连接到集群中的每个 CatalogSource</li>
<li>监视是否有用户创建的未解析 InstallPlan，如果有：
<ul>
<li>查找与请求名称相匹配的 CSV，并将此 CSC 添加为已解析的资源。</li>
<li>对于每个受管或所需 CRD，将其添加为已解析的资源。</li>
<li>对于每个所需 CRD，找到管理相应 CRD 的 CSV。</li>
</ul>
</li>
<li>监视是否有已解析的 InstallPlan 并为其创建已发现的所有资源（用户批准或自动）。</li>
<li>监视 CatalogSource 和 Subscription，并根据它们创建 InstallPlan。</li>
</ol>
</li>
<li><strong>OLM operator</strong><br>
集群中存在 CSV 中指定需要的资源后，OLM Operator 将负责部署由 CSV 资源定义的应用程序。OLM Operator 不负责创建所需资源， Catalog Operator 来创建这些资源<br>
OLM operator工作流：
<ol>
<li>监视命名空间中的 ClusterServiceVersion (CSV)，并检查是否满足要求</li>
<li>满足要求，运行CSV安装策略</li>
</ol>
<pre><code>&gt; CSV必须为og的活跃成员才可运行该安装策略
</code></pre>
</li>
<li>Catalog Registry<br>
Catalog Registry 存储 CSV 和 CRD 以便在集群中创建，并存储有关软件包和频道的元数据。</li>
</ul>
</li>
<li>OG
<ul>
<li>og成员资格，满足以下任一条件：
<ol>
<li>Operator 的 CSV 与 OperatorGroup 存在于同一命名空间中。</li>
<li>Operator 的 CSV InstallMode 支持 OperatorGroup 所针对的命名空间集。<br>
InstallMode和受支持的og
<ul>
<li>OwnNamespace：Operator 可以是选择其自有命名空间的 OperatorGroup 的成员。</li>
<li>SingleNamespace：Operator 可以是选择某一个命名空间的 OperatorGroup 的成员。</li>
<li>MultiNamespace：Operator 可以是选择多个命名空间的 OperatorGroup 的成员。</li>
<li>AllNamespaces：Operator 可以是选择所有命名空间的 OperatorGroup 的成员（目标命名空间集为空字符串 &quot;&quot;）<br>
全局 OperatorGroup 的 status.namespace 包含空字符串 (&quot;&quot;)，而该字符串会向正在使用的 Operator 发出信号，要求其监视所有命名空间。<br>
OLM 会在每个 OperatorGroup 的目标命名空间中复制 OperatorGroup 的所有活跃成员 CSV。复制 CSV 的目的在于告诉目标命名空间的用户，特定 Operator 已配置为监视在此创建的资源。</li>
</ul>
</li>
</ol>
</li>
</ul>
</li>
</ol>
<ul>
<li>基于角色的访问控制<br>
创建 OperatorGroup 时，会生成三个 ClusterRole。每个 ClusterRole 均包含一个 AggregationRule，后者设置了 ClusterRoleSelector 以匹配标签，
<ul>
<li>&lt;operatorgroup_name&gt;-admin  （olm.opgroup.permissions/aggregate-to-admin: &lt;operatorgroup_name&gt;）</li>
<li>&lt;operatorgroup_name&gt;-edit    （olm.opgroup.permissions/aggregate-to-edit: &lt;operatorgroup_name&gt;）</li>
<li>&lt;operatorgroup_name&gt;-view   （olm.opgroup.permissions/aggregate-to-view: &lt;operatorgroup_name&gt;）<br>
CSV 成为 OperatorGroup 的活跃成员时，只要该 CSV 正在使用 AllNamespaces InstallMode 来监视所有命名空间，且没有因 InterOperatorGroupOwnerConflict 原因处于故障状态，便会生成以下 RBAC 资源。</li>
<li>来自 CRD 的每个 API 资源的 ClusterRole （&lt;kind&gt;.&lt;group&gt;-&lt;version&gt;-admin &lt;kind&gt;.&lt;group&gt;-&lt;version&gt;-edit &lt;kind&gt;.&lt;group&gt;-&lt;version&gt;-view &lt;kind&gt;.&lt;group&gt;-&lt;version&gt;-view-crdview）</li>
<li>来自APIService，针对每个 API 资源生成的 ClusterRole （&lt;kind&gt;.&lt;group&gt;-&lt;version&gt;-admin &lt;kind&gt;.&lt;group&gt;-&lt;version&gt;-edit &lt;kind&gt;.&lt;group&gt;-&lt;version&gt;-view）</li>
<li>额外的role和rolebinding</li>
</ul>
</li>
<li>og交集<br>
如果两个 OperatorGroup 的目标命名空间集的交集不是空集，且根据 olm.providedAPIs 注解的定义，所提供的 API 集的交集也不是空集，则称这两个 OperatorGroup 的提供的 API 有交集。</li>
<li>og故障<br>
1. 如果一个命名空间中存在多个 OperatorGroup，则在该命名空间中创建的所有 CSV 均会变成故障状态，故障原因为：TooManyOperatorGroups。一旦命名空间中 OperatorGroup 的数量变成 1，因该原因处于故障状态的 CSV 将转变为等待处理状态。<br>
2. 如果 CSV 的 InstallMode 不支持其命名空间中 OperatorGroup 的目标命名空间选择，CSV 将变为故障状态，故障原因为 UnsupportedOperatorGroup。一旦 OperatorGroup 的目标命名空间选择变为受支持的配置，或 CSV 的 InstallMode 经修改后支持 OperatorGroup 的目标命名空间选择，因该原因处于故障状态的 CSV 将转变为等待处理状态。</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[prime filter ]]></title>
        <id>https://twFR.github.io/post/prime-fliter/</id>
        <link href="https://twFR.github.io/post/prime-fliter/">
        </link>
        <updated>2020-06-02T07:01:03.000Z</updated>
        <content type="html"><![CDATA[<p>使用并发来做一个素数筛</p>
<pre><code>package main

import &quot;fmt&quot;

func main() {
	ch :=GenerateNatural()
	for i:=0;i&lt;100;i++{
		prime := &lt;-ch                              // 第一个一定是素数
		fmt.Printf(&quot;%v: %v\n&quot;, i+1, prime)
		ch = primeFliter(ch,prime)
	}
}

// 生成一个自然数列
func GenerateNatural() chan int {
	ch := make(chan int)
	go func() {
		for i := 2; ; i++ {
			ch &lt;- i
		}
	}()
	return ch
}

// 根据prime过滤，过滤后的第一个一定是素数
func primeFliter(in &lt;- chan int,prime int) chan int{
	out := make(chan int)
	go func() {
		for {
			if i:=&lt;-in;i%prime!=0{
				out &lt;- i
			}
		}
	}()
	return out
}
</code></pre>
<p>GenerateNatural和PrimeFilter函数内部都启动了新的Goroutine，当main函数不再使用管道时后台Goroutine有泄漏的风险。可以通过context包来避免这个问题，下面是改进的素数筛实现：</p>
<pre><code>package main

import (
	&quot;context&quot;
	&quot;fmt&quot;
)

func GenerateNatural(ctx context.Context) chan int {
	ch := make(chan int)
	go func() {
		for i := 2; ; i++ {
			select {
			case &lt;-ctx.Done():
				return
			case ch &lt;- i:
			}
		}
	}()
	return ch
}

func primeFilter(ctx context.Context, in &lt;-chan int, prime int) chan int {
	out := make(chan int)
	go func() {
		for {
			if i := &lt;-in; i%prime != 0 {
				select {
				case &lt;-ctx.Done():
					return
				case out &lt;- i:
				}
			}
		}
	}()
	return out
}

func main() {

	ctx, cancel := context.WithCancel(context.Background())
	ch := GenerateNatural(ctx)
	for i := 0; i &lt; 1000; i++ {
		prime := &lt;-ch
		fmt.Printf(&quot;%v: %v\n&quot;, i+1, prime)
		ch = primeFilter(ctx, ch, prime)
	}

	cancel()   // main函数完成时，调用cancel(),通知后台goroutine退出，即ctx.Done收到信号
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[golang unsafe package]]></title>
        <id>https://twFR.github.io/post/golang-unsafe-package/</id>
        <link href="https://twFR.github.io/post/golang-unsafe-package/">
        </link>
        <updated>2020-05-08T06:27:11.000Z</updated>
        <content type="html"><![CDATA[<p>使用unsafe.Pointer来取切片的属性</p>
<pre><code>func testPointer() {
	s := make([]int, 9, 20)
	s = append(s, 2)
	len := *(*int)(unsafe.Pointer(uintptr(unsafe.Pointer(&amp;s)) + uintptr(8)))
	cap := *(*int)(unsafe.Pointer(uintptr(unsafe.Pointer(&amp;s)) + uintptr(16)))

	dataPointer := *(*int)(unsafe.Pointer(&amp;s))
	data1 := *(*int)(unsafe.Pointer(uintptr(dataPointer)))

	fmt.Printf(&quot;len: %d cap:%d \n&quot;, len, cap)
	fmt.Printf(&quot;dataPointer: %d  data1:%d \n&quot;, dataPointer, data1)

	i := 0
	for {
		if i &gt;= len {
			break
		}
		fmt.Printf(&quot;data%d:%d \n&quot;, i, *(*int)(unsafe.Pointer(uintptr(dataPointer) + uintptr(8*i))))
		i++
	}
}
</code></pre>
<p>unsafe 包绕过了 Go 的类型系统，达到直接操作内存的目的，使用它有一定的风险性。但是在某些场景下，使用 unsafe 包提供的函数会提升代码的效率，Go 源码中也是大量使用 unsafe 包。</p>
<p>unsafe 包定义了 Pointer 和三个函数：</p>
<p>通过三个函数可以获取变量的大小(Sizeof)、偏移(Offsetof)、对齐(Alignof)等信息。</p>
<p>uintptr 可以和 unsafe.Pointer 进行相互转换，uintptr 可以进行数学运算。这样，通过 uintptr 和 unsafe.Pointer 的结合就解决了 Go 指针不能进行数学运算的限制。</p>
<p>通过 unsafe 相关函数，可以获取结构体私有成员的地址，进而对其做进一步的读写操作，突破 Go 的类型安全限制。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[docker]]></title>
        <id>https://twFR.github.io/post/docker-file/</id>
        <link href="https://twFR.github.io/post/docker-file/">
        </link>
        <updated>2020-04-07T02:34:00.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p>reference: <a href="https://docs.docker.com/engine/reference/builder/">docker官方文档</a></p>
</blockquote>
<h2 id="dockerfile">dockerfile</h2>
<ul>
<li>dockerfile必须以<code>FROM</code>指令开始。<code>ARG</code>是唯一可以早于<code>FROM</code>执行的指令，查看<a href="#interact">ARG和FROM的交互</a></li>
<li>dockerfile中以<code>#</code>来标示注释，注释会在dockerfile被执行前移除掉，以免对命令产生影响</li>
</ul>
<h3 id="解析器指令">解析器指令</h3>
<p>解析器指令放在最上面，以<code># directive=value</code>的形式来声明，一旦注释 空行或者builder指令执行，docker就不会再去招解析器指令，而是把它当成注释。<br>
下面几种是不符合规范的场景：</p>
<pre><code># direc \  
 tive=value
</code></pre>
<p>△ 换行不符合规范</p>
<pre><code># directive=value1
# directive=value2
FROM ImageName
</code></pre>
<p>△ 出现两次</p>
<pre><code>FROM ImageName
# directive=value
</code></pre>
<p>△ 在builder指令后面，会被认为是注释</p>
<pre><code># About my dockerfile
# directive=value
FROM ImageName
</code></pre>
<p>△ 在注释后面，会被认为是注释</p>
<pre><code># unknowndirective=value
# knowndirective=value
</code></pre>
<p>△ 未知的解释器指令，会被认为是注释，第二行同样会被认为是注释</p>
<pre><code>#directive=value
# directive =value
#	directive= value
# directive = value
#	  dIrEcTiVe=value
</code></pre>
<p>△ 上面几种写法会被认为是同一种写法，即无视空格，不区分大小写</p>
<p>支持的解释器指令</p>
<ul>
<li>syntax<br>
# syntax=[remote image reference]<br>
这是用buldkit才会使用到的，为了指定构建当前dokcerfile的dokcerfile构建器的位置</li>
<li>escape<br>
# escape=\ (backslash) || # escape=` (backtick)<br>
escape定义转义字符，转义字符不会在<code>RUN</code>指令中执行<br>
例如在windows中将转义字符设置成`  很有用，因为windows目录格式是<code>C:\\</code>，但是在dockerfile里面会解析成<code>C:\</code>，就会找不到对应目录</li>
</ul>
<h3 id="环境变量">环境变量</h3>
<p>环境变量以$variable_name 或者 ${variable_name}格式，同样支持以下bash风格的格式：</p>
<ul>
<li>${variable:-word}  如果<code>veriable</code>设置了值，结果就是这个值。如果没有，就是<code>word</code>结果，<code>word</code>可以是定值也可以是其他变量</li>
<li>${variable:+word}  如果<code>veriable</code>设置了值，结果就是<code>word</code>。如果没有，就是空<br>
如下示例：</li>
</ul>
<pre><code>ENV abc=hello
ENV abc=bye def=$abc
ENV ghi=$abc
</code></pre>
<p><code>def</code>的值为<code>hello</code>，而 <code>ghi</code>值为<code>bye</code>官方是如下解释的</p>
<blockquote>
<p>Environment variable substitution will use the same value for each variable throughout the entire instruction. In other words</p>
</blockquote>
<p>讲道理没看特明白，但是个人土味理解应该是说每行算一个<code>entire instruction</code>,这行的值都是不会变化的，所以<code>def</code>还是用的上一行的<code>hello</code>值，而<code>ghi</code> 则可以取到上一行执行后的结果</p>
<h3 id="dockerignore-file">.dockerignore file</h3>
<p><code>.dockerignore</code> file其实和git里面的.<code>gitignore</code>文件类似，docker CLI在发送context的时候会先寻找这个文件，然后将这个文件和文件里面的指定模式的文件去除掉，不发送给docker daemon。需要注意的是<code>!</code>这个符号的用法：</p>
<pre><code>*.md                       //去掉所有md结尾的文件
!README*.md          //README开头的md文件不去除
README-secret.md  // README-secret.md作为特例要去除
</code></pre>
<p>这里表示去掉所有markdown文件。但是不去除README相关的文件，除了README-secret.md这个文件</p>
<h3 id="from">FROM</h3>
<p>三种格式：</p>
<pre><code>FROM [--platform=&lt;platform&gt;] &lt;image&gt; [AS &lt;name&gt;]
</code></pre>
<pre><code>FROM [--platform=&lt;platform&gt;] &lt;image&gt;[:&lt;tag&gt;] [AS &lt;name&gt;]
</code></pre>
<pre><code>FROM [--platform=&lt;platform&gt;] &lt;image&gt;[@&lt;digest&gt;] [AS &lt;name&gt;]
</code></pre>
<p><code>FROM</code>开始一个构建阶段，并且指定后面刚好构建指令的基础镜像</p>
<ul>
<li><code>FROM</code>可以在一个dokcerfile里面出现多次，构建多个构建镜像。只要在下一次<code>FROM</code>指令之前记住上一次image ID，两次构建就可以相互用来。每次<code>FROM</code>指令开始会清除上一次的指令</li>
<li><code>AS name</code>是可选的，如果使用了，可以在下一次的<code>FROM</code>使用 <code>COPY --from=&lt;name&gt;</code>来关联上一次的构建镜像</li>
<li><code>tag</code>和<code>digest</code>也是可选的，默认为<code>latest</code></li>
</ul>
<h4 id="a-nameinteractarg和from的交互a"><a name="interact">ARG和FROM的交互</a></h4>
<p>FROM的变量是通过ARG来定义的，所以ARG是有可能先于FROM执行的，但是此时ARG是在构建阶段之外定义的，只能在FROM指令里面使用，在其他指令使用需要在执行一次没有值的ARG</p>
<pre><code>ARG VERSION=latest
FROM busybox:$VERSION
ARG VERSION     //空值ARG取上一次ARG的值
RUN echo $VERSION &gt; image_version
</code></pre>
<h3 id="run">RUN</h3>
<p>两种格式：</p>
<pre><code>RUN &lt;command&gt;(shell form,the command is run in a shell, which by default is /bin/sh -c on Linux or cmd /S /C on Windows))
</code></pre>
<pre><code>RUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] (exec form)
</code></pre>
<p>RUN指令将在当前layer顶部的新layer执行命令，提交结果，生成的镜像将用于dockerfile下一步<br>
例：</p>
<pre><code>RUN /bin/bash -c 'source $HOME/.bashrc; echo $HOME'
</code></pre>
<pre><code>RUN [&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;echo hello&quot;]  //execform 是解析称json数组的，所以只能用&quot;，不能用'
</code></pre>
<p>execform不会调用shell，如RUN[&quot;echo,&quot;<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>H</mi><mi>O</mi><mi>M</mi><mi>E</mi><mi mathvariant="normal">&quot;</mi><mo>]</mo><mo separator="true">,</mo><mi mathvariant="normal">不</mi><mi mathvariant="normal">会</mi><mi mathvariant="normal">在</mi></mrow><annotation encoding="application/x-tex">HOME&quot;],不会在</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault" style="margin-right:0.10903em;">M</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mord">&quot;</span><span class="mclose">]</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord cjk_fallback">不</span><span class="mord cjk_fallback">会</span><span class="mord cjk_fallback">在</span></span></span></span>HOME上进行变量替换。要执行shell，需要这样：RUN [ &quot;sh&quot;, &quot;-c&quot;, &quot;echo $HOME&quot; ]。当使用execform并直接执行shell时（例如在shell表单中），是由shell进行环境变量扩展，而不是docker。<br>
RUN指令的缓存不会自动失效。 诸如RUN apt-get dist-upgrade -y之类的指令的存将在下一个构建期间重用。 可以使用--no-cache标志使RUN指令的缓存无效，例如docker build --no-cache</p>
<h3 id="cmd">CMD</h3>
<p>三种格式：</p>
<pre><code>CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;] (exec form, this is the preferred form)
</code></pre>
<pre><code>CMD [&quot;param1&quot;,&quot;param2&quot;] (as default parameters to ENTRYPOINT) //使用JSON数组格式指定，即只能使用 &quot;,不能使用'
</code></pre>
<pre><code>CMD command param1 param2 (shell form)   //在/ bin / sh -c中执行
</code></pre>
<p>CMD指令的首要目的在于为启动的容器指定默认要运行的程序，且其运行结束后，容器也将终止；不过， CMD指定的命令其可以被 docker run的命令行选项所覆盖 .在Dockerfile中可以存在多个 CMD指令，但仅最后一个会生效<br>
如果用户为docker run指定了参数，则它们将覆盖CMD中指定的默认值</p>
<h4 id="run和cmd的区别">RUN和CMD的区别</h4>
<blockquote>
<p>Do not confuse RUN with CMD. RUN actually runs a command and commits the result; CMD does not execute anything at build time, but specifies the intended command for the image.<br>
RUN执行了命令并提交了结果，但是CMD在build期间没有执行热河东西，但是为镜像指定了预期的命令</p>
</blockquote>
<h3 id="entrypoint">ENTRYPOINT</h3>
<p>两种格式：</p>
<pre><code>ENTRYPOINT [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] (exec form)
</code></pre>
<pre><code>ENTRYPOINT command param1 param2 (shell form)
</code></pre>
<p>类似 CMD指令的功能，用于为容器指定默认运行程序，从而使得容器像是一个单独的可执行程序</p>
<p>与CMD不同的是，由 ENTRYPOINT启动的程序不会被 docker run命令行指定的参数所覆盖，而且，这些命令行参数会被当作参数传递给 ENTRYPOINT指定指定的程序 ,ocker run 命令传入的命令参数会覆盖CMD指令的内容并且附加到ENTRYPOINT命令最后做为其参数使用, docker run命令的 --entrypoint选项的参数可覆盖ENTRYPOINT指令指定的程序<br>
Dockerfile文件中也可以存在多个 ENTRYPOINT指令，但仅有最后一个会生效</p>
<h4 id="cmd和entyypoint交互">CMD和ENTYYPOINT交互</h4>
<p>Dockerfile应该指定CMD或ENTRYPOINT命令中的至少一个。<br>
使用容器作为可执行文件时，应定义ENTRYPOINT。<br>
CMD应该用作定义ENTRYPOINT命令或在容器中执行临时命令的默认参数的方式。<br>
下表显示了针对不同ENTRYPOINT / CMD组合执行的命令：</p>
<table>
<thead>
<tr>
<th></th>
<th>No ENTRYPOINT</th>
<th>ENTRYPOINT exec_entry p1_entry</th>
<th>ENTRYPOINT [“exec_entry”, “p1_entry”]</th>
</tr>
</thead>
<tbody>
<tr>
<td>No CMD</td>
<td>error, not allowed</td>
<td>/bin/sh -c exec_entry p1_entry</td>
<td>exec_entry p1_entry</td>
</tr>
<tr>
<td>CMD [“exec_cmd”, “p1_cmd”]</td>
<td>exec_cmd p1_cmd</td>
<td>/bin/sh -c exec_entry p1_entry</td>
<td>exec_entry p1_entry exec_cmd p1_cmd</td>
</tr>
<tr>
<td>CMD [“p1_cmd”, “p2_cmd”]</td>
<td>p1_cmd p2_cmd</td>
<td>/bin/sh -c exec_entry p1_entry</td>
<td>exec_entry p1_entry p1_cmd p2_cmd</td>
</tr>
<tr>
<td>CMD exec_cmd p1_cmd</td>
<td>/bin/sh -c exec_cmd p1_cmd</td>
<td>/bin/sh -c exec_entry p1_entry</td>
<td>exec_entry p1_entry /bin/sh -c exec_cmd p1_cmd</td>
</tr>
</tbody>
</table>
<h3 id="copy">COPY</h3>
<p>两种形式</p>
<pre><code>COPY [--chown=&lt;user&gt;:&lt;group&gt;] &lt;src&gt;... &lt;dest&gt;
COPY [--chown=&lt;user&gt;:&lt;group&gt;] [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;]  //在路径中有空白字符时通常使用此形式
</code></pre>
<p><code>--chown</code>仅支持用户构建linux容器的dockerfile<br>
&lt;src&gt;：要复制的源文件或目录，支持使用通配符<br>
&lt;dest&gt;：目标路径，即正在创建的 image的文件系统路径；建议为 &lt;dest&gt;使用绝对路径，&lt;dest&gt;绝对路径为镜像中的路径，而不是宿主机的路径。否则， <code>COPY</code>指定则以 <code>WORKDIR</code>为其起始路径</p>
<ul>
<li>文件复制准则
<ol>
<li>&lt;src&gt;必须是build上下文中的路径，即只能放在workshop这个工作目录下，不能是其父目录中的文件</li>
<li>如果&lt;src&gt;是目录，其内部文件或者子目录会被递归复制，但&lt;src&gt;目录自身不会被复制</li>
<li>如果指定了多个&lt;src&gt;，或在&lt;src&gt;中使用了通配符，则&lt;dest&gt;必须是一个目录，且&lt;dest&gt;目录必须以<code>/</code>结尾</li>
<li>如果&lt;dest&gt;事先不存在，它将会被自动创建，这包括其父目录路径<br>
例：</li>
</ol>
</li>
</ul>
<pre><code>
[root@node1 ~]# mkdir img1/
[root@node1 ~]# cd img1/
[root@node1 img1]# ls
[root@node1 img1]# vim index.html
&lt;h1&gt;twfr.github.io &lt;/h1&gt;
[root@node1 img1]# vim Dockerfile
# Description: test image
FROM busybox:latest
MAINTAINER &quot;tanxin &lt;lovegood.xin@gmail.com&gt;&quot;
COPY index.html /data/web/html/
</code></pre>
<h3 id="add">ADD</h3>
<p>两种形式：</p>
<pre><code>ADD [--chown=&lt;user&gt;:&lt;group&gt;] &lt;src&gt;... &lt;dest&gt;
ADD [--chown=&lt;user&gt;:&lt;group&gt;] [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;]
</code></pre>
<p><code>ADD</code>指令类似于<code>COPY</code>指令， <code>ADD</code>支持使用 TAR文件和 URL路径</p>
<ul>
<li>文件操作准则，同<code>COPY</code>，另外：
<ol>
<li>如果&lt;src&gt;为URL且&lt;dest&gt;不以/结尾，则&lt;src&gt;指定的文件将被下载并直接被创建为&lt;dest&gt;；如果&lt;dest&gt;以/结尾，则文件名URL指定的文件将被直接下载，并保存为&lt;dest&gt;/&lt;filename&gt;，注意，URL不能是ftp格式的url</li>
<li>如果&lt;src&gt;是一个本地系统上的压缩格式的tar文件，它将被展开为一个目录，其行为类似于“tar -x”命令，然后，通过URL获取到的tar文件将不会自动展开</li>
<li>如果&lt;src&gt;有多个，或其间接或直接使用了通配符，则&lt;dest&gt;必须是一个以/结尾的目录路径；如果&lt;dest&gt;不以<code>/</code>结尾，则其被视作一个普通文件，&lt;src&gt;的内容将被直接写入到&lt;dest&gt;</li>
</ol>
</li>
</ul>
<h4 id="copy与add的区别">COPY与ADD的区别</h4>
<p><code>ADD</code>支持使用 TAR文件和 URL路径,支持将tar格式的压缩文件解压到指定的目录</p>
<h3 id="label">LABEL</h3>
<pre><code>LABEL &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; ...

LABEL version=&quot;1.0&quot; description=&quot;这是一个github pages&quot; by=&quot;blog&quot;
</code></pre>
<h3 id="workdir">WORKDIR</h3>
<pre><code>WORKDIR /path/to/workdir
</code></pre>
<p>WORKDIR为工作目录，可以出现多次，路径也可以为相对路径，不过，其是相对此前一个 WORKDIR指令指定的路径，还可以用由ENV定义的变量</p>
<h3 id="volume">VOLUME</h3>
<pre><code>VOLUME [&quot;/data&quot;]
</code></pre>
<p>定义卷，只能是docker管理的卷，，VOLUME为容器上的目录，用于在 image中创建一个挂载点目录，以挂载 Docker host上的卷或其它容器上的卷</p>
<h3 id="expose">EXPOSE</h3>
<pre><code>EXPOSE &lt;port&gt; [&lt;port&gt;/&lt;protocol&gt;...]
</code></pre>
<p>暴露指定端口，用于为容器打开指定要监听的端口以实现与外部通信</p>
<p>&lt;protocol&gt;用于指定传输层协议，可为 tcp或udp二者之一，默认为 TCP协议</p>
<p>EXPOSE指令可一次指定多个端口，但是不能指定暴露为宿主机的指定端口，因为指定的宿主机端口可能已经被占用，因此这里使用随机端口</p>
<pre><code>[root@node1 img1]# vim Dockerfile 
EXPOSE 80/tcp
[root@node1 ~]# docker run --name tinyweb1 --rm tinyhttpd:v0.1-6 /bin/httpd -f -h data/web/html

[root@node1 ~]# docker inspect tinyweb1                                                                                                                                         &quot;IPAddress&quot;: &quot;172.17.0.2&quot;,  

[root@node1 ~]# curl 172.17.0.2
&lt;h1&gt;twfr.github.io &lt;/h1&gt;
[root@node1 ~]# docker port tinyweb1   //没有端口信息   即没有正真暴露出来
</code></pre>
<p>启动并暴露端口，注意，启动容器要跟大写P选项-P来暴露</p>
<pre><code>[root@node1 ~]# docker run --name tinyweb1 --rm -P  tinyhttpd:v0.1-6 /bin/httpd -f -h /data/web/html

[root@node1 ~]# curl 172.17.0.2
&lt;h1&gt;twfr.github.io&lt;/h1&gt;
[root@node1 ~]# docker port tinyweb1
80/tcp -&gt; 0.0.0.0:32768
</code></pre>
<h3 id="env">ENV</h3>
<pre><code>ENV &lt;key&gt;=&lt;value&gt; ...
</code></pre>
<p>有些变量在运行为容器时依然有用，因此需要把那些变量在运行为容器时重新定义为一个新的值，如果变量很多，可以放到一个文件中进行定义，使用参数 --env-list(docker run --help )实现，通过文件来加载环境变量</p>
<pre><code>[root@node1 ~]# docker run --name tinyweb1 --rm -P -e WEB_SERVER_PACKAGE=&quot;nginx-1.15-6&quot; tinyhttpd:v0.1-7 printenv
WEB_SERVER_PACKAGE=nginx-1.15-6
</code></pre>
<h3 id="arg">ARG</h3>
<pre><code>ARG &lt;name&gt;[=&lt;default value&gt;]
</code></pre>
<p>ARG用于指定传递给构建运行时的变量</p>
<pre><code>FROM ubuntu
ARG CONT_IMG_VER
ENV CONT_IMG_VER=${CONT_IMG_VER:-v1.0.0}
RUN echo $CONT_IMG_VER
</code></pre>
<pre><code>docker build --build-arg CONT_IMG_VER=v2.0.1 .
</code></pre>
<h3 id="stopsignal">STOPSIGNAL</h3>
<pre><code>STOPSIGNAL signal
</code></pre>
<p>STOPSIGNAL用于设置停止容器所要发送的系统调用信号：<br>
所使用的信号必须是内核系统调用表中的合法的值，如：SIGKILL</p>
<h3 id="user">USER</h3>
<p>USER用于指定运行 image时的或运行 Dockerfile中任何 RUN、CMD或 ENTRYPOINT指令指定的程序时的用户名或 UID ，即改变容器中运行程序的身份<br>
默认情况下， container的运行身份为 root用户<br>
以下形式都是ok的：</p>
<pre><code>USER user
USER user:group
USER uid
USER uid:gid
USER user:gid
USER uid:group
</code></pre>
<h3 id="onbuild">ONBUILD</h3>
<pre><code>ONBUILD &lt;INSTRUCTION&gt;
</code></pre>
<p>当将映像用作另一个构建的基础时，ONBUILD指令会将触发指令添加到映像中，以便稍后执行。触发器将在下游构建的上下文中执行，就像它已被插入到下游Dockerfile中的FROM指令之后一样。</p>
<h3 id="dockerfile原则和建议">dockerfile原则和建议</h3>
<ol>
<li>容器轻量化。从镜像中产生的容器应该尽量轻量化，能在足够短的时间内停止、销毁、重新生成并替换原来的容器。</li>
<li>使用 .gitignore。在大部分情况下，Dockerfile 会和构建所需的文件放在同一个目录中，为了提高构建的性能，应该使用 .gitignore 来过滤掉不需要的文件和目录。</li>
<li>为了减少镜像的大小，减少依赖，仅安装需要的软件包。</li>
<li>一个容器只做一件事。解耦复杂的应用，分成多个容器，而不是所有东西都放在一个容器内运行。如一个 Python Web 应用，可能需要 Server、DB、Cache、MQ、Log 等几个容器。一个更加极端的说法：One process per container。</li>
<li>减少镜像的图层。不要多个 Label、ENV 等标签。</li>
<li>对续行的参数按照字母表排序，特别是使用apt-get install -y安装包的时候。</li>
<li>使用构建缓存。如果不想使用缓存，可以在构建的时候使用参数--no-cache=true来强制重新生成中间镜像。</li>
</ol>
<h2 id="docker生命周期">docker生命周期</h2>
<h3 id="镜像">镜像</h3>
<p>Docker 镜像可以看作是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。镜像不包含任何动态数据，其内容在构建之后也不会被改变。<br>
镜像（Image）就是一堆只读层（read-only layer）的统一视角，这些层是Docker 内部的实现细节，并且能够在主机的文件系统上访问到。统一文件系统 (union file system) 技术能够将不同的层整合成一个文件系统，为这些层提供了一个统一的视角，这样就隐藏了多层的存在，在用户的角度看来，只存在一个文件系统。</p>
<h3 id="容器">容器</h3>
<p>容器 (container) 的定义和镜像 (image) 几乎一模一样，也是一堆层的统一视角，唯一区别在于容器的最上面那一层是可读可写的。<br>
由于容器的定义并没有提及是否要运行容器，所以实际上，容器 = 镜像 + 读写层。</p>
<h3 id="仓库">仓库</h3>
<p>存放镜像的地方</p>
<h2 id="docker架构">docker架构</h2>
<p>核心组件包括：</p>
<ul>
<li>Docker Client<br>
客户端可以构建，运行和停止应用程序，还可以远程与Docker_Host进行交互。最常用的 Docker 客户端就是 docker 命令，我们可以通过 docker 命令很方便地在 host 上构建和运行 docker 容器。</li>
<li>Docker daemon<br>
Docker daemon 是服务器组件，以 Linux 后台服务的方式运行，是 Docker 最核心的后台进程，我们也把它称为守护进程。它负责响应来自 Docker Client 的请求，然后将这些请求翻译成系统调用完成容器管理操作。该进程会在后台启动一个 API Server ，负责接收由 Docker Client 发送的请求，接收到的请求将通过Docker daemon 内部的一个路由分发调度，由具体的函数来执行请求。<br>
docker daemon又可以分为docker server engine和job三部分<br>
ocker Daemon 可以认为是通过 Docker Server 模块接受 Docker Client 的请求，并在 Engine 中处理请求，然后根据请求类型，创建出指定的 Job 并运行。 Docker Daemon 运行在 Docker host 上，负责创建、运行、监控容器，构建、存储镜像。</li>
<li>Docker Image</li>
<li>Docker Registry</li>
<li>Docker Container<br>
容器启动的过程大致如下：</li>
</ul>
<ol>
<li>Docker 客户端执行 docker run 命令</li>
<li>Docker daemon 发现本地没有我们需要的镜像</li>
<li>daemon 从指定的镜像仓库下载镜像</li>
<li>下载完成后，镜像被保存到本地</li>
<li>Docker daemon 启动容器</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[priority queue]]></title>
        <id>https://twFR.github.io/post/priority-queue/</id>
        <link href="https://twFR.github.io/post/priority-queue/">
        </link>
        <updated>2020-03-25T01:41:25.000Z</updated>
        <content type="html"><![CDATA[<p>优先队列，即不按进栈顺序，按优先级出栈，又分为最大优先级队列和最小优先级队列</p>
<p>golang可以使用heap堆操作来实现一个优先级队列</p>
<p>heap的堆结构如下：</p>
<pre><code>type Interface interface {
    sort.Interface
    Push(x interface{}) 
    Pop() interface{}   
}
</code></pre>
<p>故只需要实现sort的三个方法，和push，pop方法，即可实现一个优先级队列</p>
<pre><code>
package main

import (
	&quot;container/heap&quot;
	&quot;fmt&quot;
)

type stu struct {
	name string
	age  int
}
type Stu []stu

func (t *Stu) Len() int {
	return len(*t)
}

func (t *Stu) Less(i, j int) bool {
	return (*t)[i].age &lt; (*t)[j].age
}
func (t *Stu) Swap(i, j int) {
	(*t)[i], (*t)[j] = (*t)[j], (*t)[i]
}

func (t *Stu) Push(x interface{}) {
	*t = append(*t, x.(stu))
}
func (t *Stu) Pop() interface{} {
	n := len(*t)
	x := (*t)[n-1]
	*t = (*t)[:n-1]
	return x
}
func main() {
	student := &amp;Stu{{&quot;Amy&quot;, 21}, {&quot;Dav&quot;, 15}, {&quot;Spo&quot;, 22}, {&quot;Reb&quot;, 11}}
	heap.Init(student)
	one := stu{&quot;hund&quot;, 9}
	heap.Push(student, one)
	for student.Len() &gt; 0 {
		fmt.Printf(&quot;%v\n&quot;, heap.Pop(student))
	}
}
</code></pre>
<p>上面是一个最小优先级队列。把less里面改改，就是一个最大优先级了，当然，不太符合编程规范，哈哈。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ k8s summary]]></title>
        <id>https://twFR.github.io/post/k8s-summary/</id>
        <link href="https://twFR.github.io/post/k8s-summary/">
        </link>
        <updated>2020-03-14T13:57:21.000Z</updated>
        <content type="html"><![CDATA[<p>Kubernetes 提供了一个可弹性运行分布式系统的框架。 Kubernetes 会满足扩展要求、故障转移、部署模式等，提供以下服务</p>
<ul>
<li>服务发现和负载均衡</li>
<li>存储编排</li>
<li>自动部署和回滚</li>
<li>自动完成装箱计算</li>
<li>自我修复</li>
<li>密钥与配置管理</li>
</ul>
<h2 id="组件">组件</h2>
<ul>
<li>
<p>控制面组件（管理面）</p>
<ol>
<li>kube-apiserver  服务器，提供API</li>
<li>kube- controler-manager
<ul>
<li>node controller：负责节点出现故障时进行通知和响应</li>
<li>replication controller：负责为系统中每个副本控制器对象维护正确数量的pod</li>
<li>endpoint controller：填充endpoints对象（即加入service与pod）</li>
<li>service account&amp; token contolers：为新的命名空间传家默认账户和API访问令牌</li>
</ul>
</li>
<li>kube-scheduler 监视新创建  未指定node的pods，选择node让pod运行</li>
<li>etcd  保存集群数据</li>
</ol>
</li>
<li>
<p>Node组件（数据面）</p>
<ol>
<li>kubelet  每个node上的代理。保证containers都运行在pod中。接收一组提供给kubelet的PodSpecs，确保PodSpecs描述的容器处于运行状态且健康。不会管理不是kubernets创建的容器</li>
<li>kube-proxy 每个节点上运行的网络代理，维护节点上的网络规则</li>
</ol>
</li>
<li>
<p>Container Runtime 负责运行容器的软件（docker containers CRI-O）</p>
</li>
<li>
<p>插件（Addons）</p>
<p>插件使用 Kubernetes 资源（<a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/daemonset/">DaemonSet</a>、 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/deployment/">Deployment</a>等）实现集群功能。如DNS，Dashboard</p>
</li>
</ul>
<h2 id="架构">架构</h2>
<h3 id="节点">节点</h3>
<ul>
<li>
<p>可用节点上都包括kubelet，Container Runtime及kube-proxy</p>
</li>
<li>
<p>向API服务器添加节点的方式主要有两种：</p>
<ol>
<li>
<p>节点上的kubelet向控制面执行自注册</p>
<p>当 kubelet 标志 <code>--register-node</code> 为 true（默认）时，它会尝试向 API 服务注册自己</p>
</li>
<li>
<p>手动注册<br>
执行操作后，控制面会检查新的node对象是否合法。 如果节点是健康的（即所有必要的服务都在运行中），则该节点可以用来运行 Pod。 否则，直到该节点变为健康之前，所有的集群活动都会忽略该节点。</p>
</li>
</ol>
</li>
</ul>
<h3 id="控制面节点通信">控制面节点通信</h3>
<ul>
<li>
<p>节点到控制面<br>
Kubernetes 采用的是中心辐射型（Hub-and-Spoke）API 模式。 所有从集群（或所运行的 Pods）发出的 API 调用都终止于 apiserver（其它控制面组件都没有被设计为可暴露远程服务）。 apiserver 被配置为在一个安全的 HTTPS 端口（443）上监听远程连接请求。应该使用集群的公共根证书开通节点，这样它们就能够基于有效的客户端凭据安全地连接 apiserver。<br>
当 Pod 被实例化时，Kubernetes 自动把公共根证书和一个有效的持有者令牌注入到 Pod 里。kubernetes 服务（位于所有名字空间中）配置了一个虚拟 IP 地址，用于（通过 kube-proxy）转发 请求到 apiserver 的 HTTPS 末端。<br>
控制面组件也通过安全端口与集群的 apiserver 通信。<br>
集群节点和节点上运行的 Pod 到控制面的连接的缺省操作模式即是安全的， 能够在不可信的网络或公网上运行。</p>
</li>
<li>
<p>控制面到节点</p>
<ol>
<li>
<p>API服务器到kubelet</p>
<p>从apiserver到kubelet的连接用于：</p>
<ul>
<li>获取pod日志</li>
<li>挂接（通过kubectl）到运行中的pod</li>
<li>通过kubelet的端口转发功能<br>
这些连接终止于 kubelet 的 HTTPS 末端。 默认情况下，apiserver 不检查 kubelet 的服务证书。这使得此类连接容易受到中间人攻击， 在非受信网络或公开网络上运行也是 不安全的。</li>
</ul>
</li>
<li>
<p>apiserver到节点，pod和服务</p>
<p>从 apiserver 到节点、Pod 或服务的连接默认为纯 HTTP 方式，因此既没有认证，也没有加密，这些连接 <strong>目前还不能安全地</strong> 在非受信网络或公共网络上运行。</p>
</li>
</ol>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[GO GMP]]></title>
        <id>https://twFR.github.io/post/go-gmp/</id>
        <link href="https://twFR.github.io/post/go-gmp/">
        </link>
        <updated>2020-01-20T12:50:03.000Z</updated>
        <content type="html"><![CDATA[<p><code>M</code>指<code>machine</code>，一个<code>M</code>直接关联一个内核线程，有操作系统管理</p>
<p><code>P</code>值<code>processor</code>,代表了<code>M</code>所需要的上下文环境，也是处理用户级代码逻辑的处理器，负责衔接<code>M</code>和<code>G</code>的调度上下文，将等待执行的<code>G</code>与<code>M</code>对接。一般来说，<code>P</code>的数量由环境变量中<code>GOMAXPROCS</code>决定，通常与核心数对应</p>
<p><code>G</code>就是<code>goroutine</code> ，包括了调用栈，重要的调度信息，如channel等</p>
<p>一个<code>M</code>会对应一个内核线程，一个M也会链接一个上下文<code>P</code>，一个上下文<code>P</code>又会连接一个或者多个<code>G</code>形成runqueues。通过关键字<code>go</code>启动一个<code>G</code>加入runqueues队列末尾，一旦上下文运行到调度点，<code>Goroutine</code>会从runqueues弹出，设置堆栈和指令指针开始运行<code>Goroutine</code></p>
<p>如果<code>M0</code>遇到一个syscall内核线程阻塞，这时候<code>M0</code>会放弃当前的上下文环境<code>P0</code>，<code>P0</code>会被其它<code>M</code>（新创建或者线程缓存）接受，以便让<code>P0</code>下面的<code>Goroutine</code>能被调度执行。而当<code>M0</code> syscall结束后，会尝试去偷一个上下文<code>P</code>，如果不成功，会把先面刚刚执行的<code>G</code>放到全局的<code>Goroutine</code>然后自己置于线程缓存中进入休眠状态。</p>
<p>P会周期性检查全局的runqueues队列里面的<code>Goroutine</code>，以便在消费自身<code>Goroutine</code>队列后继续执行全局runqueues，如果全局也没有了，P在跑完自己runqueues之后，会去其它的<code>P</code>中偷一半过来</p>
<blockquote>
<p><a href="https://segmentfault.com/a/1190000018775901">扩展，大神详解go调度器</a></p>
</blockquote>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[GC]]></title>
        <id>https://twFR.github.io/post/golang-gc/</id>
        <link href="https://twFR.github.io/post/golang-gc/">
        </link>
        <updated>2020-01-18T11:53:12.000Z</updated>
        <content type="html"><![CDATA[<p>三种经典GC算法：</p>
<ul>
<li>
<p>引用计数：<br>
把所有单元放在一个单元池。这样所有的单元就串起来了，就可以进行引用计数了。新分配的单元计数值被设置为1（注意不是 0，因为申请一般都说 ptr = new object 这种）。每次有一个指针被设为指向该单元时，该单元计数值加1；而每次删除某个指向它的指针时，它的计数值减1.当其引用数为0的的时候，该单元被回收。<br>
优点：</p>
<ul>
<li>渐进式。内存管理与用户程序的执行交织在一起，将 GC 的代价分散到整个程序。不像标记-清扫算法需要 STW (Stop The World，GC 的时候挂起用户程序)。</li>
<li>算法易于实现</li>
<li>内存单元能够很快被回收。相比于其他垃圾回收算法，堆被耗尽或者达到某个阈值才会进行垃圾回收。<br>
缺点：</li>
<li>原始的引用计数不能处理循环引用。</li>
<li>维护引用计数降低运行效率。内存单元的更新删除等都需要维护相关的内存单元的引用计数，相比于一些追踪式的垃圾回收算法并不需要这些代价。</li>
<li>单元池 free list 实现的话不是 cache-friendly 的，这样会导致频繁的 cache miss，降低程序运行效率。</li>
</ul>
</li>
<li>
<p>标记-清扫算法<br>
自动内存管理，基于追踪的垃圾收集算法。内存单元并不会在变成垃圾立刻回收，而是保持不可达状态，直到到达某个阈值或者固定时间长度。这个时候系统会挂起用户程序，也就是 STW，转而执行垃圾回收程序。算法分两个部分：标记（mark）和清扫（sweep）。标记阶段表明所有的存活单元，清扫阶段将垃圾单元回收。</p>
</li>
<li>
<p>三色标记算法<br>
对标记算法的改进</p>
<ol>
<li>起初所有的对象都是白的</li>
<li>从根出发扫描所有可达对象，将其置灰放入一个队列里面</li>
<li>然后从这个队列里面取对象，将本身置黑放入另一个队列，将他的引用对象标灰放入灰队列里面</li>
<li>重复3，直到灰为空。白色即为垃圾，进行回收</li>
</ol>
<p>根对象如何而来呢，生命周期可以保证的对象是根对象，<font color=red><strong>线程栈</strong></font>本身就是一个根,线程栈里面可能存了某个对象的指针，那线程栈就会引用那个对象，所以像全局变量，线程栈这些就是根对象。</p>
<ul>
<li>
<p>回收可以和用户逻辑并发：<br>
扫描结束后只有黑白对象，黑对象是需要使用的，不需要动。白色是肯定不会被使用的垃圾，所有用户线程肯定都不会使用，所以回收操作和用户逻辑是可以并发的。所以回收操作不放在STW的时间里面</p>
</li>
<li>
<p>扫描也可以和用户逻辑并发-- hybrid write barrier（混合写屏障）：<br>
该屏障之前的写操作和之后的写操作相比，先被系统其它组件感知<br>
刚把一个对象标为白色，用户逻辑突然引用了它，这时就用到写屏障。先做一次简单的STW，执行简单的状态处理，接下来对内存扫描，这个时候用户逻辑就可以执行了。所有新建的对象直接置黑不管，下一次再说，已经扫描过的对象可能因此发生状态改变，所以对扫描过后的对象使⽤操作系统写屏障功能⽤来监控⽤户逻辑这段内存。任何时候这段内存发⽣引⽤改变的时候就会造成写屏障发⽣⼀个信号，垃圾回收器会捕获到这样的信号后就知道这个对象发⽣改变，然后重新扫描这个对象，看看它的引⽤或者被引⽤是否被改变。这样看来，扫描操作也是可以和用户逻辑并发的</p>
</li>
<li>
<p>辅助回收<br>
如果扫描的速度跟不上用户分配的速度，会造成扫描永远结束不了，这种情况会导致内存膨胀。出现这种情况，go还是会把用户逻辑暂停，然后把用户线程抢过来加入垃圾回收提升速度，这就是辅助回收。</p>
</li>
</ul>
</li>
</ul>
]]></content>
    </entry>
</feed>